{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1A8MhXtJTGi"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqZP7THdu4MS"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip show transformers\n",
        "%pip show accelerate\n",
        "%pip install transformers[torch] -U\n",
        "%pip install accelerate -U\n",
        "%pip install transformers\n",
        "%pip install pytorch-lightning\n",
        "%pip install --upgrade transformers\n",
        "%pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERNlGyweKUhm"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfScIJapKW5X",
        "outputId": "1390ab50-5650-4854-c6cf-29bda7c7cd09"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import os\n",
        "import gdown\n",
        "\n",
        "\n",
        "# 1. Prepare Dataset\n",
        "# 2. Load pretrained Tokenizer, call it with dataset -> encoding\n",
        "# 3. Build PyTorth Dataset with encodings\n",
        "# 4. Load pretrained Model\n",
        "# 5. Load HF Trainer and train it\n",
        "\n",
        "file_id = '1E5v6t-y2Pzeyi5C-amlYibp2cXUN0MLW'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "file_path = 'all_data.csv'\n",
        "if not os.path.exists(file_path):\n",
        "    # Download the file\n",
        "    gdown.download(url, file_path, quiet=False)\n",
        "\n",
        "# Read the csv file\n",
        "all_data = pd.read_csv(file_path, engine='python')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "toxicity_train_df, toxicity_test_df = train_test_split(all_data, test_size=0.40, random_state=42)\n",
        "\n",
        "# List of categories to check\n",
        "categories_to_check = ['obscene', 'sexual_explicit', 'threat', 'insult', 'identity_attack']\n",
        "\n",
        "toxicity_train_df[categories_to_check] = toxicity_train_df[categories_to_check].apply(pd.to_numeric, errors='coerce')\n",
        "toxicity_test_df[categories_to_check] = toxicity_test_df[categories_to_check].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Check if any category is above the 0.33 threshold\n",
        "toxicity_train_df['toxic'] = (toxicity_train_df[categories_to_check] >= 0.33).any(axis=1).astype(float)\n",
        "toxicity_test_df['toxic'] = (toxicity_test_df[categories_to_check] >= 0.33).any(axis=1).astype(float)\n",
        "\n",
        "# Convert boolean values to 1.0 for True and 0.0 for False\n",
        "toxicity_train_df['toxic'] = toxicity_train_df['toxic'].astype(float)\n",
        "toxicity_test_df['toxic'] = toxicity_test_df['toxic'].astype(float)\n",
        "\n",
        "toxicity_train_df = toxicity_train_df[['comment_text', 'toxic', 'obscene', 'sexual_explicit', 'threat', 'insult', 'identity_attack']]\n",
        "toxicity_test_df = toxicity_test_df[['comment_text', 'toxic', 'obscene', 'sexual_explicit', 'threat', 'insult', 'identity_attack']]\n",
        "\n",
        "# Can be adjusted to downsample training data\n",
        "sample_rate = 1.0\n",
        "\n",
        "toxicity_train_df = toxicity_train_df.sample(frac=sample_rate, random_state=42)\n",
        "\n",
        "print(\"Toxic train examples\")\n",
        "print(toxicity_train_df.head(4))\n",
        "\n",
        "print(\"Toxic test examples\")\n",
        "print(toxicity_test_df.head(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckNEOfOt7JY0"
      },
      "source": [
        "Test Lengths of DFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEr4-GKc7LG4",
        "outputId": "690e5068-da5c-4b56-dc27-078cf1810669"
      },
      "outputs": [],
      "source": [
        "print(len(toxicity_train_df))\n",
        "# print(len(toxicity_test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCaSSAkv-L2D"
      },
      "source": [
        "# Visualization of toxicity in train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "Wh3Wr23h-Nwl",
        "outputId": "06c4333c-ba39-4fc5-a7b8-dae8aa14f600"
      },
      "outputs": [],
      "source": [
        "# Count toxic and non-toxic comments\n",
        "toxic_count = toxicity_train_df['toxic'].sum()\n",
        "non_toxic_count = len(toxicity_train_df) - toxic_count\n",
        "\n",
        "# Plot side-by-side bars for toxic and non-toxic comments\n",
        "labels = ['Toxic Comments', 'Non-Toxic Comments']\n",
        "counts = [toxic_count, non_toxic_count]\n",
        "\n",
        "plt.bar(labels, counts, color=['red', 'blue'])\n",
        "plt.ylabel('Comment Count')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQBDfIDTAVmi"
      },
      "source": [
        "# Visualization of toxicity in test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "vMgpw28TAYN6",
        "outputId": "54a743e7-fde6-4c07-c1a7-81c9039afa45"
      },
      "outputs": [],
      "source": [
        "# # Count toxic and non-toxic comments\n",
        "# toxic_count = toxicity_test_df['toxic'].sum()\n",
        "# non_toxic_count = len(toxicity_test_df) - toxic_count\n",
        "\n",
        "# # Plot side-by-side bars for toxic and non-toxic comments\n",
        "# labels = ['Toxic Comments', 'Non-Toxic Comments']\n",
        "# counts = [toxic_count, non_toxic_count]\n",
        "\n",
        "# plt.bar(labels, counts, color=['red', 'blue'])\n",
        "# plt.ylabel('Comment Count')\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWP0mBB9ZFf4"
      },
      "source": [
        "# Splitting and Labelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LUVKLSjZKHn",
        "outputId": "2c90ef76-9c00-4d86-de95-618e01402663"
      },
      "outputs": [],
      "source": [
        "model_name = \"roberta-base\"\n",
        "\n",
        "# Reset index to ensure consistency\n",
        "toxicity_train_df.reset_index(drop=True, inplace=True)\n",
        "# toxicity_test_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Select relevant columns from DataFrame and drop NaN values\n",
        "train_data = toxicity_train_df[['comment_text', 'toxic']].dropna()\n",
        "# test_data = toxicity_test_df[['comment_text', 'toxic']].dropna()\n",
        "\n",
        "# Extract features and labels\n",
        "train_texts = train_data['comment_text'].tolist()\n",
        "train_labels = train_data['toxic'].tolist()\n",
        "# test_texts = test_data['comment_text'].tolist()\n",
        "# test_labels = test_data['toxic'].tolist()\n",
        "\n",
        "# Print examples of texts & labels\n",
        "print(\"train_texts:\")\n",
        "print(train_texts[:5])\n",
        "print(\"train_labels:\")\n",
        "print(train_labels[:5])\n",
        "# print(\"test_texts\")\n",
        "# print(test_texts[:5])\n",
        "# print(\"test_labels:\")\n",
        "# print(test_labels[:5])\n",
        "\n",
        "# Split train data into train and validation sets\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PaVNtTit2tc"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758,
          "referenced_widgets": [
            "861da291e2084362a00b05a928f5b57b",
            "6a7d4fa147e74871a21dbb4ee5a353fb",
            "ee7b76a0bc6c4a4dba659100df1c09cc",
            "71ffb97f0bfb43ca8dce48eac582d6a4",
            "5b3c8c081de34fdc8232097c91302959",
            "7806d6aef3384a95bbcb059026675b41",
            "4b8a142ac6734ec7be44aa9eab704f54",
            "4d7038e38a9744c996ecf23313db90e7",
            "c377693c7d2246f9897c4dc11a58220a",
            "4062f1c3e24e46b994579201868f1808",
            "acdc79b1ab4a4c50a968bc5a1fba5321",
            "9a2aed7188104aff98c54719dd021070",
            "96b9e76620cd47148ccce1d8797221f3",
            "e091b5a251244d40b9bbbb526ef96efc",
            "65c1165edbb3402eb34df5e4dabd1d7c",
            "e037d6fd15234cf79d58cac63e5af9ce",
            "07f5c33c79e84d549a4a811d26fea600",
            "4836d62b4e084cd381c06ab2dfdee2e4",
            "e5ed7fdb32244798ba1fee43664c6b07",
            "d95e46ccaca2474b8d7be4e45ef8a0e6",
            "8e9ec62850d446fa9bdca90329d601e7",
            "1780cccf94454549925d62aef8a7d509",
            "85b9bc4d86984031916de614f50e4066",
            "47c5ecde15cf414f8a64584481ebaca1",
            "be4b2303100047dc8e06eff0ef408272",
            "3f06cbd465bc48a9959403a5af3d3ac8",
            "49bfd54efdbd49e185d852874d45b5f5",
            "1810f3f8e653444d835204d0cf40eb3b",
            "debb3fdcf84941db8c33237bffb6e807",
            "6153f6b9e2e44c9f817a19c64800a125",
            "2637afb72efc4afc89094aaf79ab36dc",
            "dd76675ac7b94ff0bd4000a8b6e60d65",
            "1841c5ce234548e28720a17345a73214",
            "db9cef9976b4412788705df75556a2d7",
            "d36dc922720a4b86b828eb4abf00a154",
            "e092379b6482464d955cca2f53c65c77",
            "e0071103de184a92b86c4d39f1e9c338",
            "473ae49ca3824b54adeaed2766a8858d",
            "8234948dad6148829bbf4d612faa55bf",
            "75e95696ae84420e8edfe6cc29df9248",
            "27192ce0964f402aa831e0933053ebda",
            "e214bd6657414291a39d4ed39a95aac5",
            "90097f2f6b6342c6bb00afb88b3aa1cc",
            "c9d2299f42ff415fb14bf2e520d31f2c",
            "3e931a4475d6421bae6c1648a486a580",
            "5d458a133366465097e0a81302ae6ee8",
            "1c762652db104eb6968c0638d6f2172b",
            "bc51d348e8c54caf99c15e14068e0fb7",
            "b8910cf7e8ff406fa4595ce96f53f5f7",
            "e3b62d42149a42a485e01c3defd5c61b",
            "71f022bc04c94c83a51dba65467c1972",
            "fe4d1aa1302d438cb826a4bdf96a0c62",
            "b11cb51d253e4296a6fb89d8ddba74ee",
            "e5c232d524464dec8e0667b8c57de142",
            "41ac3ca4bc184212b66f1f63453a89da"
          ]
        },
        "id": "m54fSxNKt4oC",
        "outputId": "bcc67c5a-c9a7-42c3-fec9-d7d8a5fea187"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "\n",
        "\n",
        "class ToxicDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx]).float()\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
        "# test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
        "\n",
        "train_dataset = ToxicDataset(train_encodings, train_labels)\n",
        "val_dataset = ToxicDataset(val_encodings, val_labels)\n",
        "# test_dataset = ToxicDataset(test_encodings, test_labels)\n",
        "\n",
        "print(\"Train Dataset\")\n",
        "# Iterate over train_dataset and print some samples\n",
        "for i in range(2):  # Print first 2 samples\n",
        "    sample = train_dataset[i]\n",
        "    print(f\"Sample {i + 1}:\")\n",
        "    # Convert input_ids tensor to list and access its keys\n",
        "    encoding_keys = tokenizer.convert_ids_to_tokens(sample[\"input_ids\"].tolist())\n",
        "    print(\"Encoding keys:\", encoding_keys)  # Print keys of encoding\n",
        "    print(\"Label:\", sample[\"labels\"].item())  # Print label\n",
        "    print()\n",
        "\n",
        "print(\"Val Dataset\")\n",
        "# Iterate over val dataset and print some samples\n",
        "for i in range(2):  # Print first 2 samples\n",
        "    sample = val_dataset[i]\n",
        "    print(f\"Sample {i + 1}:\")\n",
        "    # Convert input_ids tensor to list and access its keys\n",
        "    encoding_keys = tokenizer.convert_ids_to_tokens(sample[\"input_ids\"].tolist())\n",
        "    print(\"Encoding keys:\", encoding_keys)  # Print keys of encoding\n",
        "    print(\"Label:\", sample[\"labels\"].item())  # Print label\n",
        "    print()\n",
        "\n",
        "print(\"Test Dataset\")\n",
        "# Iterate over test dataset and print some samples\n",
        "for i in range(2):  # Print first 2 samples\n",
        "    # sample = test_dataset[i]\n",
        "    # print(f\"Sample {i + 1}:\")\n",
        "    # Convert input_ids tensor to list and access its keys\n",
        "    encoding_keys = tokenizer.convert_ids_to_tokens(sample[\"input_ids\"].tolist())\n",
        "    print(\"Encoding keys:\", encoding_keys)  # Print keys of encoding\n",
        "    print(\"Label:\", sample[\"labels\"].item())  # Print label\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9EcJcm1nJkP"
      },
      "source": [
        "# Native PyTorch (instead of HF Trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqw8qYpfmtl_",
        "outputId": "64a6f67e-0e9c-4f2f-ed14-d6edf233b314"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import RobertaTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import AdamW\n",
        "import torch\n",
        "import random\n",
        "\n",
        "# Set random seed for reproducability\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Access GPU or CPU depending on status\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# Grab generic roberta-base model to be fine tuned\n",
        "model = AutoModelForSequenceClassification.from_pretrained('roberta-base', num_labels=1)\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "# Initialize training params\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "optim = AdamW(model.parameters(), lr=1e-5)\n",
        "num_train_epochs = 1\n",
        "\n",
        "# Set the gradient accumulation steps\n",
        "gradient_accumulation_steps = 16  # Adjust as needed\n",
        "\n",
        "# Fine-tuned roberta-base model\n",
        "for epoch in range(num_train_epochs):\n",
        "  total_loss = 0.0\n",
        "  for batch_idx, batch in enumerate(train_loader):\n",
        "      input_ids = batch['input_ids'].to(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      labels = batch['labels'].to(device)\n",
        "\n",
        "      outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "      loss = outputs[0] / gradient_accumulation_steps  # Normalize the loss\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform an optimization step only after a certain number of steps\n",
        "      if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
        "          optim.step()\n",
        "          optim.zero_grad()\n",
        "\n",
        "      if (batch_idx + 1) % 50 == 0:  # Print progress every 50 batches\n",
        "          print(f\"Epoch [{epoch + 1}/{num_train_epochs}], Batch [{batch_idx + 1}/{len(train_loader)}], Loss: {total_loss / (batch_idx + 1):.4f}\")\n",
        "\n",
        "  print(f\"Epoch [{epoch + 1}/{num_train_epochs}], Average Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Store the fine-tuned model for later use\n",
        "model.save_pretrained('usr/fine_tuned_roberta')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECHyv7V2o9ye"
      },
      "source": [
        "Download file paths (if desired)\n",
        "\n",
        "Sometimes can alter the json file and cause the subsequent code cells to fail. Hence, commented out for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "8juZkK6dcn6m",
        "outputId": "57412e89-1582-4dd4-8cf8-fb4201167585"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# # Paste the path you copied as the argument to files.download()\n",
        "\n",
        "# from tqdm import tqdm\n",
        "# from google.colab import files\n",
        "\n",
        "# # File paths to download\n",
        "# file_paths = ['/usr/fine_tuned_roberta_model_2/config.json', '/usr/fine_tuned_roberta_model_2/model.safetensors']\n",
        "\n",
        "# # Loop through each file and download with tqdm progress bar\n",
        "# for file_path in file_paths:\n",
        "#     with open(file_path, 'wb') as f:\n",
        "#         with tqdm(unit='B', unit_scale=True, unit_divisor=1024, miniters=1,\n",
        "#                   desc=file_path.split('/')[-1]) as pbar:\n",
        "#             # Download the file\n",
        "#             files.download(file_path)\n",
        "#             # Manually update progress bar\n",
        "#             pbar.update()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60_Yekc0nJdh"
      },
      "source": [
        "# Default RoBERTa test as baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfSPaPT-zglZ",
        "outputId": "17a6b1b6-2107-4346-b51a-0b4998d949b4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import RobertaTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import random\n",
        "\n",
        "# Set a fixed state for randomness\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Load the tokenizer and model for inference\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('roberta-base')\n",
        "\n",
        "\n",
        "# Move the model to CPU if it's on CUDA device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Put the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Function to convert LABEL_0 to 'no'\n",
        "def convert_label(prediction):\n",
        "    return 'no' if prediction[0]['label'] == 'LABEL_0' else 'yes'\n",
        "\n",
        "global count\n",
        "count = 0\n",
        "\n",
        "def predict_label(row):\n",
        "    global count\n",
        "    text_to_predict = row['comment_text']\n",
        "\n",
        "    encoding = tokenizer(text_to_predict, return_tensors='pt', padding=True, truncation=True)\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.sigmoid(logits).cpu().numpy().flatten()\n",
        "    binary_label = 1 if ((np.abs(probabilities[1] - probabilities[0]) <= 0.061) and (probabilities[0] < 0.5425)) else 0\n",
        "    count = count + 1\n",
        "    if (count % 1000 == 0):\n",
        "      print(count)\n",
        "    if(count < 10):\n",
        "      # Print out some examples of stream comments and their respective probabilities and label (toxic/non-toxic)\n",
        "      print(text_to_predict)\n",
        "      print(probabilities)\n",
        "      # The difference in probabilities represents a confidence interval which is also important to evaluate\n",
        "      print(np.abs(probabilities[1] - probabilities[0]))\n",
        "      print(binary_label)\n",
        "    return binary_label\n",
        "\n",
        "# Load the Twitch dataset\n",
        "twitch_df = pd.read_csv('hasanAbiTest.csv')\n",
        "print(len(twitch_df))\n",
        "\n",
        "# Apply the prediction function to each row in the DataFrame\n",
        "twitch_df['base_prediction'] = twitch_df.apply(predict_label, axis=1)\n",
        "\n",
        "# Assuming 'LABEL_0' corresponds to 'no'\n",
        "prediction_counts = twitch_df['base_prediction'].value_counts()\n",
        "print(prediction_counts)\n",
        "\n",
        "# Print the counts\n",
        "print(\"Count of 'no':\", prediction_counts[0.0])\n",
        "print(\"Count of 'yes':\", prediction_counts[1.0])  # Adjust the label if needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ipCWIyGLDfq"
      },
      "source": [
        "# Base Toxic Word Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "id": "YDHo9RJ-LL3Q",
        "outputId": "09101f05-848b-4711-c76f-2da2907d242c"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "# Download NLTK resources (run only once)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "print(twitch_df.info())\n",
        "\n",
        "# Filter toxic comments\n",
        "toxic_comments = twitch_df[twitch_df['base_prediction'] == 1]['comment']\n",
        "print(toxic_comments.head(5))\n",
        "\n",
        "# Initialize NLTK stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Extend the stop words list with additional common words to exclude\n",
        "additional_stop_words = ['today', \"don't\", 'like', 'know', 'and', 'the',\n",
        "                         'get', 'HasanAbi', 'hasanabi', 'Hasan', 'hasan', 'Abi',\n",
        "                         'dont', ',', 'got', 'cant', 'make',\n",
        "                         'see', 'im', 'make', 'think', 'one', 'every',\n",
        "                         'take', 'day', 'really', 'Tier', 'tier', 'Tier 1',\n",
        "                         '1', 'Theyve', 'theyve', 'going', 'subscribed', 'months']  # Add more words as needed\n",
        "stop_words.update(additional_stop_words)\n",
        "\n",
        "# Remove punctuation from comments\n",
        "def remove_punctuation(text):\n",
        "    return ''.join([char for char in text if char not in string.punctuation])\n",
        "\n",
        "cleaned_comments = ' '.join([comment for comment in toxic_comments])\n",
        "cleaned_comments = remove_punctuation(cleaned_comments)\n",
        "\n",
        "# Tokenize the cleaned comments\n",
        "tokens = nltk.word_tokenize(cleaned_comments)\n",
        "\n",
        "# Remove stop words\n",
        "tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "# Calculate word frequencies\n",
        "freq_dist = nltk.FreqDist(tokens)\n",
        "\n",
        "# Generate the word cloud with frequencies\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(freq_dist)\n",
        "\n",
        "# Plot the word cloud\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzL8EQmjdZao",
        "outputId": "d0edad07-04ca-4fc0-c42d-1a8b5ba8f11f"
      },
      "outputs": [],
      "source": [
        "!pip install better-profanity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgA8eGog8O1S"
      },
      "source": [
        "# Fine-Tuned Roberta on Cleaned UWB Review Dataset stream dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rodAVSjc8RRu",
        "outputId": "0122803c-43d5-4050-ed2d-68c45d6f66f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total length of test: 10002\n",
            "It's not hard class, but don't expect the 4.0. She isn't clear about what is expected and the syllabus changed multiple times over the quarter. You can tell she doesn't take business students seriously and makes you feel awkward about your responses which really discourages participation.\n",
            "0.5382911\n",
            "0\n",
            "Syllabus was clear on what the daily homework was, which was a huge help for the quarter! Would recommend uploading her powerpoint presentations before her class to stay keep up with lectures; what she says verbally shows up on the midterms! Also reading the textbook helped!! Overall, good professor but her lectures are a bore.\n",
            "0.538291\n",
            "0\n",
            "Bridge is the coolest prof I've ever had. His joy and passion of the subjects he teaches is next level. He's always telling stories that relate to the subject in interesting ways. Easy grader and really cares that the students fully understand, and succeed in his course. Clear and fair expectations, do the homeworks and you'll excel on the exams.\n",
            "0.53829175\n",
            "0\n",
            "Bridge makes it abundantly clear what you need to know to get a good grade. If you listen to him and take notes you can do well in any of his classes. He is forgiving and understanding so long as you make the effort. If you don't show up... good luck. The most fair professor I have ever had. Hell of a person and tells the best stories!\n",
            "0.53829074\n",
            "1\n",
            "One of the best professors I have ever had. Truly cares about his students.\n",
            "0.53828883\n",
            "0\n",
            "A true teacher. His passion for the material and desire to share it with students is infectious. Very knowledgeable, has years of industry experience and amazing stories. Most respected professor I have had.\n",
            "0.5382918\n",
            "0\n",
            "Awesome teacher! Print out his pre-made class guide and take notes on those. He always points out the necessary equations and does at least one practice problem with the class so you can look at it during hw. Do the hw and the tests are straightforward from there. However, no online notes so attendance is needed.\n",
            "0.53829044\n",
            "0\n",
            "Very long and boring lectures which cover little new material, but a bit more in depth coverage of material from 5 course prerequisites.  DETAILS are key.  Get the textbook from India for $30, it's low quality and the homework problems may be a bit different, but all you really need are the tables.\n",
            "0.5382908\n",
            "0\n",
            "I like him. He gets a bit distracted talking about his past experiences but you'll end up with funny stories. Tests are pretty straightforward and open book, and lectures are pretty clear.\n",
            "0.5382912\n",
            "0\n",
            "Laid back guy, cracks jokes and is helpful all the time\n",
            "0.53829795\n",
            "0\n",
            "He is very clear with his expectations & his grading scale which is nice. However there always seems to be something on the exam that was barely covered or unexpected. A pretty harsh grader, docks you 10 pts for seemingly innocent mistakes. My advice is to visit him in office hours (very helpful there) a lot. Takes a while to get him but he's fun.\n",
            "0.5382908\n",
            "0\n",
            "I've had three classes with him 315: The class is poorly structured and exams don't correlate well with material, but its not entirely his fault because the ME program lacks some areas of knowledge which he tries to squeeze into this course 343: Difficult material and lectures but he does a solid job 223: Fantastic dynamics teacher\n",
            "0.538298\n",
            "0\n",
            "His grading can be rather harsh, but given the set up of the class you should be OK. We were given weekly quizzes (problems straight off of the HW) and those quizzes combined ended up equaling more than the one midterm he gave.   Do ample practice problems from the actual textbook and the optional textbook and you'll be just fine. Go to lecture.\n",
            "0.53829145\n",
            "0\n",
            "Hilarious due to the extreme disconnect between material instructed and major grading assignments.  Didn't really expect a 3d design, modelling, and analysis class to focus so much on design and modelling, yet grade so heavily on Technical Writing, and Linear Algebra.  A complete lack of textbook for the class also served little help.\n",
            "0.53829014\n",
            "0\n",
            "I like him as a person, but he has no idea what he is doing in class. I understand that the ME program is new, but this class as a whole is pointless. The class is called '3D modeling' but tests have nothing to do with actual modeling. The entire class was still working on the final at the end of the 2nd hour.\n",
            "0.5382907\n",
            "0\n",
            "THE BEST TEACHER I WILL definitely take this class again\n",
            "0.5382898\n",
            "0\n",
            "Professor Oh seems like a great guy, but I have not enjoyed his class. It's very lecture heavy with limited/no slides, which can be really hard to follow. He frequently asks questions of the class where no one is clear what he's asking for -- after 5 or 6 attempts he'll finally tell us the \"answer\", which isn't what he asked for at all...\n",
            "0.5382915\n",
            "0\n",
            "This is not at easy class. But Dr. Oh is a really good teacher. He is a very easy grader when it comes to homework, make sure you study hard on the midterm and final. Hes a really nice, laid back and funny guy. Only problem Ive had was he speaks with a REALLY thick Korean accent and sometimes it might be hard to understand what hes saying.\n",
            "0.53829\n",
            "1\n",
            "Professor Oh is a great teacher but hard to understand sometimes. I had never taken a business class before 210 and I enjoyed it. It did feel a little weird if you had questions about something and his response was along the lines of \"this is it, this is how you do it, how do you not understand?\" Posts almost everything from class online for review\n",
            "0.53829247\n",
            "0\n",
            "Hyung is an awesome prof, his lectures are super engaging and funny. Even if you sit in the back, you will end up participating. The hw is graded literally on completion, and the exam questions are literally straight out of the hw. If you get the hw you'll ace the test. There is also extra credit on each exam worth 10%, extremely generous easy q's.\n",
            "0.5382894\n",
            "0\n",
            "Dr. Oh is awesome. He is funny and tries his best to teach students that accounting is \"fun and useful\". The course consists of ten HW assignments and three exams (2 midterms, 1 final). The homework was graded very easily.. I only missed 1 point. The exams are straight-forward and questions come from homework/review q's. Extra credit on exams!\n",
            "0.5382929\n",
            "0\n",
            "This is a great class. Very short homework and there is always one question he throughly goes over in class. Huge chance that its going to be the same question on the test. Tests arent hard but for the final go over all the homework assignments because he might copy and paste a random question from those.\n",
            "0.5382913\n",
            "0\n",
            "He gets right to the point. Probably one of the best professors ive had. His tests are short and does not take the full 2 hours, and there are extra credit questions on them to. Be aware, getting above a hundred percent only gives you a hundred percent (not 109). Homework is short. He sometimes teaches us stuff not relevant, but still interesting!\n",
            "0.53829265\n",
            "0\n",
            "Prof. Oh is an okay teacher. He tries to help us but his lecture is boring and he has a strong Korean accent. He stress that accounting is useful and fun to motivate us. He seems like developing his teaching skills yet but he still has some room to improve. I do not recommend his class. He is not horrible but not awesome.\n",
            "0.53828984\n",
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "roberta_UWBR_prediction\n",
            "0    9618\n",
            "1     384\n",
            "Name: count, dtype: int64\n",
            "Count of 'no': 9618\n",
            "Count of 'yes': 384\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import RobertaTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import random\n",
        "from better_profanity import profanity\n",
        "\n",
        "# Set a fixed state for randomness\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)  # If using CUDA\n",
        "\n",
        "# Load the tokenizer and model for inference\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('fine_tuned_roberta')\n",
        "\n",
        "# Move the model to CPU if it's on CUDA device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Put the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Function to convert LABEL_0 to 'no'\n",
        "def convert_label(prediction):\n",
        "    return 'no' if prediction[0]['label'] == 'LABEL_0' else 'yes'\n",
        "\n",
        "def contains_profanity(text):\n",
        "    return profanity_check.predict([text])[0]\n",
        "\n",
        "global count\n",
        "global sub_mention\n",
        "sub_mention = False\n",
        "profanity_in = False\n",
        "count = 0\n",
        "\n",
        "def predict_label(row):\n",
        "    global count\n",
        "    global sub_mention\n",
        "    text_to_predict = row['Review-Body']\n",
        "    if pd.isnull(text_to_predict):\n",
        "      text_to_predict = \"No Comments\" \n",
        "    # Filter out mentionings of Twitch subscriptions and tiers\n",
        "    sub_mention = any(keyword in text_to_predict for keyword in [\"Tier 1\", \"subscribed with Prime\", \"subbed using Prime\"])\n",
        "    # Leverages better profanity to catch additional profanity occurences\n",
        "    profanity_in = profanity.contains_profanity(text_to_predict)\n",
        "    encoding = tokenizer(text_to_predict, return_tensors='pt', padding=True, truncation=True)\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.sigmoid(logits).cpu().numpy().flatten()\n",
        "    binary_label = 1 if profanity_in or (np.abs(probabilities[0]) > 0.56 and not sub_mention) else 0\n",
        "    count = count + 1\n",
        "    if (count % 1000 == 0):\n",
        "      print(count)\n",
        "    if(count < 25):\n",
        "      # Print out some examples of stream comments and their respective probabilities and label (toxic/non-toxic)\n",
        "      print(text_to_predict)\n",
        "      print(np.abs(probabilities[0]))\n",
        "      print(binary_label)\n",
        "    return binary_label\n",
        "\n",
        "# Load the Twitch dataset\n",
        "twitch_df = pd.read_csv('Cleaned_UW_RMP.csv')\n",
        "print(f\"Total length of test: {len(twitch_df)}\")\n",
        "\n",
        "# Apply the prediction function to each row in the DataFrame\n",
        "twitch_df['roberta_UWBR_prediction'] = twitch_df.apply(predict_label, axis=1)\n",
        "\n",
        "prediction_counts = twitch_df['roberta_UWBR_prediction'].value_counts()\n",
        "print(prediction_counts)\n",
        "\n",
        "# Print the counts\n",
        "print(\"Count of 'no':\", prediction_counts[0.0])\n",
        "print(\"Count of 'yes':\", prediction_counts[1.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYg7iiHEIZNf"
      },
      "source": [
        "Note the ***detection of new toxic words*** not found in previous stream: Lefters, Libbers, Hoggers (assuming political connotations).\n",
        "\n",
        "Note the ***detection of user toxicity*** such as \"Yelling at Trolls\", and \"I'm not trolling\", \"CLICKBAIT\".\n",
        "\n",
        "Note the filtering out of typical Twitch platform messages subscription mentioning: \"Tier 1, has subscribed, etc\".\n",
        "\n",
        "See Excel file for more details if curious."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZrIc4M6EMzp"
      },
      "source": [
        "Save Predictions for Fine-Tuned Wikipedia Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Tp30-AokERiM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openpyxl in c:\\users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages (3.1.3)\n",
            "Requirement already satisfied: et-xmlfile in c:\\users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openpyxl\n",
        "# Define the file path for the Excel file\n",
        "excel_file_path = \"/usr/roberta_UWBR_predictions.xlsx\"\n",
        "\n",
        "# Save the 'roberta_wiki_prediction' column to an Excel file\n",
        "twitch_df['roberta_UWBR_prediction'].to_excel(excel_file_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhFsI8gFLTjn"
      },
      "source": [
        "# Fine-Tuned Wikipedia Toxic Word Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "eJwuzcFwLYbd",
        "outputId": "9fc61713-5ba9-44aa-d53d-2faf1c4770ee"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "# Download NLTK resources (run only once)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Filter toxic comments\n",
        "toxic_comments = twitch_df[twitch_df['roberta_wiki_prediction'] == 1]['comment']\n",
        "print(toxic_comments.head(5))\n",
        "\n",
        "batch_size = 1000  # Set the batch size\n",
        "num_rows = len(twitch_df)\n",
        "with open('union_output.txt', 'w') as f:\n",
        "    for start in range(0, num_rows, batch_size):\n",
        "        end = min(start + batch_size, num_rows)\n",
        "        for index, row in twitch_df.iloc[start:end].iterrows():\n",
        "            f.write(str(row['roberta_wiki_prediction']) + '\\n')\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download('union_output.txt')\n",
        "\n",
        "# Initialize NLTK stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Extend the stop words list with additional common words to exclude\n",
        "additional_stop_words = ['today', \"don't\", 'like', 'know', 'and', 'the',\n",
        "                         'get', 'HasanAbi', 'hasanabi', 'Hasan', 'hasan', 'Abi',\n",
        "                         'dont', ',', 'got', 'cant', 'make',\n",
        "                         'see', 'im', 'make', 'think', 'one', 'every',\n",
        "                         'take', 'day', 'really']  # Add more words as needed\n",
        "stop_words.update(additional_stop_words)\n",
        "\n",
        "# Remove punctuation from comments\n",
        "def remove_punctuation(text):\n",
        "    return ''.join([char for char in text if char not in string.punctuation])\n",
        "\n",
        "cleaned_comments = ' '.join([comment for comment in toxic_comments])\n",
        "cleaned_comments = remove_punctuation(cleaned_comments)\n",
        "\n",
        "# Tokenize the cleaned comments\n",
        "tokens = nltk.word_tokenize(cleaned_comments)\n",
        "\n",
        "# Remove stop words\n",
        "tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "# Calculate word frequencies\n",
        "freq_dist = nltk.FreqDist(tokens)\n",
        "\n",
        "# Generate the word cloud with frequencies\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(freq_dist)\n",
        "\n",
        "# Plot the word cloud\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prbHe2ke_sJZ"
      },
      "source": [
        "# Preprocessing on Twitch Union dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q7VWNih_xYV",
        "outputId": "57d17fd0-c77b-4ed1-9c21-e8c55214d92f"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# 1. Prepare Dataset\n",
        "# 2. Load pretrained Tokenizer, call it with dataset -> encoding\n",
        "# 3. Build PyTorth Dataset with encodings\n",
        "# 4. Load pretrained Model\n",
        "# 5. Load HF Trainer and train it\n",
        "\n",
        "# Train Data (Roberta + Llama Union), 11449 rows\n",
        "toxicity_train_df = pd.read_csv('toxic_union.csv',  on_bad_lines='skip')\n",
        "toxicity_train_df = toxicity_train_df.dropna()\n",
        "\n",
        "# Test Data - 7287 rows after pre-processing\n",
        "toxicity_test_df = pd.read_csv('toxicity_test.csv', on_bad_lines='skip', quoting=csv.QUOTE_NONE)\n",
        "toxicity_test_df = toxicity_test_df.dropna()\n",
        "\n",
        "# Only check these categories in toxicity_test since train is our union csv\n",
        "# built from the previous fine-tuning and training cells\n",
        "categories_to_check = ['obscene', 'sexual_explicit', 'threat', 'insult', 'identity_attack']\n",
        "\n",
        "toxicity_test_df[categories_to_check] = toxicity_test_df[categories_to_check].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Check if any category is above the 0.33 threshold\n",
        "toxicity_test_df['toxic'] = (toxicity_test_df[categories_to_check] >= 0.33).any(axis=1).astype(float)\n",
        "toxicity_test_df['toxic'] = toxicity_test_df['toxic'].astype(float)\n",
        "toxicity_test_df = toxicity_test_df[['comment_text', 'toxic', 'obscene', 'sexual_explicit', 'threat', 'insult', 'identity_attack']]\n",
        "\n",
        "print(\"Toxic train examples\")\n",
        "print(toxicity_train_df.head(4))\n",
        "\n",
        "print(\"Toxic test examples\")\n",
        "print(toxicity_test_df.head(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cFDObnXpwqm"
      },
      "source": [
        "Test DF lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkhGq7HqMhLC",
        "outputId": "6c3c88b7-f2b8-4371-e3fe-43c7d9fa8cf5"
      },
      "outputs": [],
      "source": [
        "print(len(toxicity_train_df))\n",
        "print(len(toxicity_test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcLMOYf6Eaqf"
      },
      "source": [
        "# Visualization of Toxicity in Union Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "bnpI6vCREizW",
        "outputId": "0f6f5455-0c97-4669-a423-0f1f69f36cd7"
      },
      "outputs": [],
      "source": [
        "# Count toxic and non-toxic comments\n",
        "toxic_count = toxicity_train_df['union'].sum()\n",
        "non_toxic_count = len(toxicity_train_df) - toxic_count\n",
        "\n",
        "# Plot side-by-side bars for toxic and non-toxic comments\n",
        "labels = ['Toxic Comments', 'Non-Toxic Comments']\n",
        "counts = [toxic_count, non_toxic_count]\n",
        "\n",
        "plt.bar(labels, counts, color=['red', 'blue'])\n",
        "plt.ylabel('Comment Count')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BKaGeUaEw1w"
      },
      "source": [
        "# Union Dataset Wordcloud\n",
        "\n",
        "***What are the most common toxic words in our Union Dataset?***\n",
        "\n",
        "Union Dataset: Represents the union of Llama 7-b zero-shot labeling, and RoBERTa NLP model fine-tuned on Wikipedia comments on toxic Twitch comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "kXb3w4KdEzda",
        "outputId": "586c3227-afb0-4e22-d60d-2bc5cdc3f7d5"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "# Download NLTK resources (run only once)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Filter toxic comments\n",
        "toxic_comments = toxicity_train_df[toxicity_train_df['union'] == 1]['comment_text']\n",
        "print(toxic_comments.head(5))\n",
        "\n",
        "# Initialize NLTK stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Extend the stop words list with additional common words to exclude\n",
        "additional_stop_words = ['today', \"don't\", 'like', 'know', 'and', 'the',\n",
        "                         'get', 'HasanAbi', 'hasanabi', 'Hasan', 'hasan', 'Abi',\n",
        "                         'dont', ',', 'got', 'cant', 'make',\n",
        "                         'see', 'im', 'make', 'think', 'one', 'every',\n",
        "                         'take', 'day', 'really', 'Tier', 'tier', 'Tier 1',\n",
        "                         '1', 'Theyve', 'theyve', 'going', 'subscribed', 'months']  # Add more words as needed\n",
        "stop_words.update(additional_stop_words)\n",
        "\n",
        "# Remove punctuation from comments\n",
        "def remove_punctuation(text):\n",
        "    return ''.join([char for char in text if char not in string.punctuation])\n",
        "\n",
        "cleaned_comments = ' '.join([comment for comment in toxic_comments])\n",
        "cleaned_comments = remove_punctuation(cleaned_comments)\n",
        "\n",
        "# Tokenize the cleaned comments\n",
        "tokens = nltk.word_tokenize(cleaned_comments)\n",
        "\n",
        "# Remove stop words\n",
        "tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "# Calculate word frequencies\n",
        "freq_dist = nltk.FreqDist(tokens)\n",
        "\n",
        "# Generate the word cloud with frequencies\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(freq_dist)\n",
        "\n",
        "# Plot the word cloud\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1YXDyrvAcEQ"
      },
      "source": [
        "# Splitting & Labeling + Dataset creation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxlgXZ0JAsrX",
        "outputId": "0e692efc-90db-47ee-8578-1d03e25835e9"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "\n",
        "# Reset index to ensure consistency\n",
        "toxicity_train_df.reset_index(drop=True, inplace=True)\n",
        "toxicity_test_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Select relevant columns from DataFrame and drop NaN values\n",
        "train_data = toxicity_train_df[['comment_text', 'union']].dropna()\n",
        "test_data = toxicity_test_df[['comment_text', 'toxic']].dropna()\n",
        "\n",
        "# Extract features and labels\n",
        "train_texts = train_data['comment_text'].tolist()\n",
        "train_labels = train_data['union'].tolist()\n",
        "test_texts = test_data['comment_text'].tolist()\n",
        "test_labels = test_data['toxic'].tolist()\n",
        "\n",
        "# Print examples of texts & labels\n",
        "print(\"train_texts:\")\n",
        "print(train_texts[:5])\n",
        "print(\"train_labels:\")\n",
        "print(train_labels[:5])\n",
        "print(\"test_texts\")\n",
        "print(test_texts[:5])\n",
        "print(\"test_labels:\")\n",
        "print(test_labels[:5])\n",
        "\n",
        "# Split train data into train and validation sets\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2)\n",
        "\n",
        "\n",
        "class ToxicDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx]).float()\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
        "\n",
        "train_dataset = ToxicDataset(train_encodings, train_labels)\n",
        "val_dataset = ToxicDataset(val_encodings, val_labels)\n",
        "test_dataset = ToxicDataset(test_encodings, test_labels)\n",
        "\n",
        "print(\"Train Dataset\")\n",
        "# Iterate over train_dataset and print some samples\n",
        "for i in range(2):  # Print first 2 samples\n",
        "    sample = train_dataset[i]\n",
        "    print(f\"Sample {i + 1}:\")\n",
        "    # Convert input_ids tensor to list and access its keys\n",
        "    encoding_keys = tokenizer.convert_ids_to_tokens(sample[\"input_ids\"].tolist())\n",
        "    print(\"Encoding keys:\", encoding_keys)  # Print keys of encoding\n",
        "    print(\"Label:\", sample[\"labels\"].item())  # Print label\n",
        "    print()\n",
        "\n",
        "print(\"Val Dataset\")\n",
        "# Iterate over val dataset and print some samples\n",
        "for i in range(2):  # Print first 2 samples\n",
        "    sample = val_dataset[i]\n",
        "    print(f\"Sample {i + 1}:\")\n",
        "    # Convert input_ids tensor to list and access its keys\n",
        "    encoding_keys = tokenizer.convert_ids_to_tokens(sample[\"input_ids\"].tolist())\n",
        "    print(\"Encoding keys:\", encoding_keys)  # Print keys of encoding\n",
        "    print(\"Label:\", sample[\"labels\"].item())  # Print label\n",
        "    print()\n",
        "\n",
        "print(\"Test Dataset\")\n",
        "# Iterate over test dataset and print some samples\n",
        "for i in range(2):  # Print first 2 samples\n",
        "    sample = test_dataset[i]\n",
        "    print(f\"Sample {i + 1}:\")\n",
        "    # Convert input_ids tensor to list and access its keys\n",
        "    encoding_keys = tokenizer.convert_ids_to_tokens(sample[\"input_ids\"].tolist())\n",
        "    print(\"Encoding keys:\", encoding_keys)  # Print keys of encoding\n",
        "    print(\"Label:\", sample[\"labels\"].item())  # Print label\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIbBWay5BWT2"
      },
      "source": [
        "# Training on Union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyH82OeDBuKz",
        "outputId": "f1383efa-aff6-48ce-c821-e815d8e6417b"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import RobertaTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import AdamW\n",
        "import torch\n",
        "\n",
        "# Set random seed for reproducability\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# Access the once fine-tuned RoBERTa model we just created\n",
        "# (not the same as RoBERTa toxicity standard used below see desc for explanation)\n",
        "model = AutoModelForSequenceClassification.from_pretrained('/usr/fine_tuned_roberta_model')\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "# Initialize training parameters\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "optim = AdamW(model.parameters(), lr=1e-6)\n",
        "num_train_epochs = 1\n",
        "\n",
        "# Train on the union of Llama 7-b and RoBERTa toxicity standard\n",
        "for epoch in range(num_train_epochs):\n",
        "  total_loss = 0.0\n",
        "  for batch_idx, batch in enumerate(train_loader):\n",
        "      optim.zero_grad()\n",
        "      input_ids = batch['input_ids'].to(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      labels = batch['labels'].to(device)\n",
        "\n",
        "      outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "      loss = outputs[0]\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "\n",
        "      if (batch_idx + 1) % 50 == 0:  # Print progress every 50 batches\n",
        "          print(f\"Epoch [{epoch + 1}/{num_train_epochs}], Batch [{batch_idx + 1}/{len(train_loader)}], Loss: {total_loss / (batch_idx + 1):.4f}\")\n",
        "\n",
        "  print(f\"Epoch [{epoch + 1}/{num_train_epochs}], Average Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "model.save_pretrained('/usr/fine_tuned_roberta_model_union')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfQ5N02B-4zI"
      },
      "source": [
        "***How are the RoBERTa models different?***\n",
        "\n",
        "Great question. The RoBERTa models vary in that the first one created focuses on the fine-tuning using a toxicity definition that focuses on five specific sub-categories of toxicity (insult, threat, obscene, identity_hate, sexually_explicit). This gives us a more focused definition for toxicity than the [RoBERTa toxicity standard model](https://huggingface.co/s-nlp/roberta_toxicity_classifier), which also uses Wikipedia comments, but has a more generalizable definition of toxic and features much more data. Thus, the Union represents the Union of Llama 7-b with the RoBERTa standard model as both should have a lot more context and generalizability than the once fine-tuned version of RoBERTa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-uWSB4fB0Ny"
      },
      "source": [
        "# Fine-tuned Union (RoBERTa / Llama) Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25Nw-yFYCbt6",
        "outputId": "7202a946-1840-4410-93f1-a6fb287b245a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import RobertaTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import random\n",
        "from better_profanity import profanity\n",
        "\n",
        "# Set a fixed state for randomness\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Load the tokenizer and model for inference\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('/usr/fine_tuned_roberta_model_union')\n",
        "\n",
        "# Move the model to CPU if it's on CUDA device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Put the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Function to convert LABEL_0 to 'no'\n",
        "def convert_label(prediction):\n",
        "    return 'no' if prediction[0]['label'] == 'LABEL_0' else 'yes'\n",
        "\n",
        "# Returns whether text contains profanity\n",
        "def contains_profanity(text):\n",
        "    return profanity_check.predict([text])[0]\n",
        "\n",
        "global count\n",
        "global sub_mention\n",
        "sub_mention = False\n",
        "profanity_in = False\n",
        "count = 0\n",
        "\n",
        "def predict_label(row):\n",
        "    global count\n",
        "    global sub_mention\n",
        "    text_to_predict = row['comment']\n",
        "    # Remove any generic Twitch platform subscription comments\n",
        "    sub_mention = any(keyword in text_to_predict for keyword in [\"Tier 1\", \"subscribed with Prime\", \"subbed using Prime\"])\n",
        "    # Employ profanity checker for more robust toxic comment detection in case some words or acronyms\n",
        "    # are missed initially by classifier\n",
        "    profanity_in = profanity.contains_profanity(text_to_predict)\n",
        "    encoding = tokenizer(text_to_predict, return_tensors='pt', padding=True, truncation=True)\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.sigmoid(logits).cpu().numpy().flatten()\n",
        "    binary_label = 1 if profanity_in or (np.abs(probabilities[0]) > 0.577 and not sub_mention) or (np.abs(probabilities[0]) < 0.551 and not sub_mention) else 0\n",
        "    count = count + 1\n",
        "    if (count % 1000 == 0):\n",
        "      print(count)\n",
        "    if(count < 20):\n",
        "      # Print out some examples of stream comments and their respective probabilities and label (toxic/non-toxic)\n",
        "      print(text_to_predict)\n",
        "      print(np.abs(probabilities[0]))\n",
        "      print(binary_label)\n",
        "    return binary_label\n",
        "\n",
        "# Load the Twitch dataset\n",
        "twitch_df = pd.read_csv('hasan_abi_11.19.22_test.csv')\n",
        "print(len(twitch_df))\n",
        "\n",
        "# Apply the prediction function to each row in the DataFrame\n",
        "twitch_df['union_prediction'] = twitch_df.apply(predict_label, axis=1)\n",
        "\n",
        "# Grab prediction counts\n",
        "prediction_counts = twitch_df['union_prediction'].value_counts()\n",
        "print(prediction_counts)\n",
        "\n",
        "# Print the counts\n",
        "print(\"Count of 'no':\", prediction_counts[0.0])\n",
        "print(\"Count of 'yes':\", prediction_counts[1.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ci1MzbboS7iI"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjEw6E37S8HN"
      },
      "outputs": [],
      "source": [
        "# Define the file path for the Excel file\n",
        "excel_file_path = \"/usr/roberta_union_predictions_final.xlsx\"\n",
        "\n",
        "# Save the 'roberta_wiki_prediction' column to an Excel file\n",
        "twitch_df['union_prediction'].to_excel(excel_file_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI5gubWCCeZS"
      },
      "source": [
        "# Double fine-tuned WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "vTvd_EwoChU_",
        "outputId": "dde054f0-df1c-4a7a-93ec-e852eb89a86f"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "# Download NLTK resources (run only once)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Filter toxic comments\n",
        "toxic_comments = twitch_df[twitch_df['union_prediction'] == 1]['comment']\n",
        "print(toxic_comments.head(5))\n",
        "\n",
        "from google.colab import files\n",
        "files.download('union_output.txt')\n",
        "\n",
        "# Initialize NLTK stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Extend the stop words list with additional common words to exclude\n",
        "additional_stop_words = ['today', \"don't\", 'like', 'know', 'and', 'the',\n",
        "                         'get', 'HasanAbi', 'hasanabi', 'Hasan', 'hasan', 'Abi',\n",
        "                         'dont', ',', 'got', 'cant', 'make', 'hes', 'back',\n",
        "                         'see', 'im', 'make', 'think', 'one', 'every', 'running',\n",
        "                         'take', 'day', 'really', 'Trump', 'EPISODE', 'PODCAST', 'Episode',\n",
        "                         'Podcast', 'leftovers', 'trump', 'episode', 'podcast']  # Add more words as needed\n",
        "stop_words.update(additional_stop_words)\n",
        "\n",
        "# Remove punctuation from comments\n",
        "def remove_punctuation(text):\n",
        "    return ''.join([char for char in text if char not in string.punctuation])\n",
        "\n",
        "cleaned_comments = ' '.join([comment for comment in toxic_comments])\n",
        "cleaned_comments = remove_punctuation(cleaned_comments)\n",
        "\n",
        "# Convert all words to lowercase before removing stopwords\n",
        "tokens = [word.lower() for word in tokens]\n",
        "\n",
        "# Remove stop words\n",
        "tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "# Calculate word frequencies\n",
        "freq_dist = nltk.FreqDist(tokens)\n",
        "\n",
        "# Generate the word cloud with frequencies\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(freq_dist)\n",
        "\n",
        "# Plot the word cloud\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07f5c33c79e84d549a4a811d26fea600": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1780cccf94454549925d62aef8a7d509": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1810f3f8e653444d835204d0cf40eb3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1841c5ce234548e28720a17345a73214": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c762652db104eb6968c0638d6f2172b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe4d1aa1302d438cb826a4bdf96a0c62",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b11cb51d253e4296a6fb89d8ddba74ee",
            "value": 481
          }
        },
        "2637afb72efc4afc89094aaf79ab36dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27192ce0964f402aa831e0933053ebda": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e931a4475d6421bae6c1648a486a580": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d458a133366465097e0a81302ae6ee8",
              "IPY_MODEL_1c762652db104eb6968c0638d6f2172b",
              "IPY_MODEL_bc51d348e8c54caf99c15e14068e0fb7"
            ],
            "layout": "IPY_MODEL_b8910cf7e8ff406fa4595ce96f53f5f7"
          }
        },
        "3f06cbd465bc48a9959403a5af3d3ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd76675ac7b94ff0bd4000a8b6e60d65",
            "placeholder": "​",
            "style": "IPY_MODEL_1841c5ce234548e28720a17345a73214",
            "value": " 456k/456k [00:00&lt;00:00, 19.4MB/s]"
          }
        },
        "4062f1c3e24e46b994579201868f1808": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41ac3ca4bc184212b66f1f63453a89da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "473ae49ca3824b54adeaed2766a8858d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47c5ecde15cf414f8a64584481ebaca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1810f3f8e653444d835204d0cf40eb3b",
            "placeholder": "​",
            "style": "IPY_MODEL_debb3fdcf84941db8c33237bffb6e807",
            "value": "merges.txt: 100%"
          }
        },
        "4836d62b4e084cd381c06ab2dfdee2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49bfd54efdbd49e185d852874d45b5f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b8a142ac6734ec7be44aa9eab704f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d7038e38a9744c996ecf23313db90e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b3c8c081de34fdc8232097c91302959": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d458a133366465097e0a81302ae6ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3b62d42149a42a485e01c3defd5c61b",
            "placeholder": "​",
            "style": "IPY_MODEL_71f022bc04c94c83a51dba65467c1972",
            "value": "config.json: 100%"
          }
        },
        "6153f6b9e2e44c9f817a19c64800a125": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65c1165edbb3402eb34df5e4dabd1d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e9ec62850d446fa9bdca90329d601e7",
            "placeholder": "​",
            "style": "IPY_MODEL_1780cccf94454549925d62aef8a7d509",
            "value": " 899k/899k [00:00&lt;00:00, 11.0MB/s]"
          }
        },
        "6a7d4fa147e74871a21dbb4ee5a353fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7806d6aef3384a95bbcb059026675b41",
            "placeholder": "​",
            "style": "IPY_MODEL_4b8a142ac6734ec7be44aa9eab704f54",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "71f022bc04c94c83a51dba65467c1972": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71ffb97f0bfb43ca8dce48eac582d6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4062f1c3e24e46b994579201868f1808",
            "placeholder": "​",
            "style": "IPY_MODEL_acdc79b1ab4a4c50a968bc5a1fba5321",
            "value": " 25.0/25.0 [00:00&lt;00:00, 1.25kB/s]"
          }
        },
        "75e95696ae84420e8edfe6cc29df9248": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7806d6aef3384a95bbcb059026675b41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8234948dad6148829bbf4d612faa55bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85b9bc4d86984031916de614f50e4066": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47c5ecde15cf414f8a64584481ebaca1",
              "IPY_MODEL_be4b2303100047dc8e06eff0ef408272",
              "IPY_MODEL_3f06cbd465bc48a9959403a5af3d3ac8"
            ],
            "layout": "IPY_MODEL_49bfd54efdbd49e185d852874d45b5f5"
          }
        },
        "861da291e2084362a00b05a928f5b57b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a7d4fa147e74871a21dbb4ee5a353fb",
              "IPY_MODEL_ee7b76a0bc6c4a4dba659100df1c09cc",
              "IPY_MODEL_71ffb97f0bfb43ca8dce48eac582d6a4"
            ],
            "layout": "IPY_MODEL_5b3c8c081de34fdc8232097c91302959"
          }
        },
        "8e9ec62850d446fa9bdca90329d601e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90097f2f6b6342c6bb00afb88b3aa1cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96b9e76620cd47148ccce1d8797221f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07f5c33c79e84d549a4a811d26fea600",
            "placeholder": "​",
            "style": "IPY_MODEL_4836d62b4e084cd381c06ab2dfdee2e4",
            "value": "vocab.json: 100%"
          }
        },
        "9a2aed7188104aff98c54719dd021070": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96b9e76620cd47148ccce1d8797221f3",
              "IPY_MODEL_e091b5a251244d40b9bbbb526ef96efc",
              "IPY_MODEL_65c1165edbb3402eb34df5e4dabd1d7c"
            ],
            "layout": "IPY_MODEL_e037d6fd15234cf79d58cac63e5af9ce"
          }
        },
        "acdc79b1ab4a4c50a968bc5a1fba5321": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b11cb51d253e4296a6fb89d8ddba74ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8910cf7e8ff406fa4595ce96f53f5f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc51d348e8c54caf99c15e14068e0fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5c232d524464dec8e0667b8c57de142",
            "placeholder": "​",
            "style": "IPY_MODEL_41ac3ca4bc184212b66f1f63453a89da",
            "value": " 481/481 [00:00&lt;00:00, 24.5kB/s]"
          }
        },
        "be4b2303100047dc8e06eff0ef408272": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6153f6b9e2e44c9f817a19c64800a125",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2637afb72efc4afc89094aaf79ab36dc",
            "value": 456318
          }
        },
        "c377693c7d2246f9897c4dc11a58220a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9d2299f42ff415fb14bf2e520d31f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d36dc922720a4b86b828eb4abf00a154": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8234948dad6148829bbf4d612faa55bf",
            "placeholder": "​",
            "style": "IPY_MODEL_75e95696ae84420e8edfe6cc29df9248",
            "value": "tokenizer.json: 100%"
          }
        },
        "d95e46ccaca2474b8d7be4e45ef8a0e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db9cef9976b4412788705df75556a2d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d36dc922720a4b86b828eb4abf00a154",
              "IPY_MODEL_e092379b6482464d955cca2f53c65c77",
              "IPY_MODEL_e0071103de184a92b86c4d39f1e9c338"
            ],
            "layout": "IPY_MODEL_473ae49ca3824b54adeaed2766a8858d"
          }
        },
        "dd76675ac7b94ff0bd4000a8b6e60d65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "debb3fdcf84941db8c33237bffb6e807": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0071103de184a92b86c4d39f1e9c338": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90097f2f6b6342c6bb00afb88b3aa1cc",
            "placeholder": "​",
            "style": "IPY_MODEL_c9d2299f42ff415fb14bf2e520d31f2c",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 14.9MB/s]"
          }
        },
        "e037d6fd15234cf79d58cac63e5af9ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e091b5a251244d40b9bbbb526ef96efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5ed7fdb32244798ba1fee43664c6b07",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d95e46ccaca2474b8d7be4e45ef8a0e6",
            "value": 898823
          }
        },
        "e092379b6482464d955cca2f53c65c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27192ce0964f402aa831e0933053ebda",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e214bd6657414291a39d4ed39a95aac5",
            "value": 1355863
          }
        },
        "e214bd6657414291a39d4ed39a95aac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3b62d42149a42a485e01c3defd5c61b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5c232d524464dec8e0667b8c57de142": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5ed7fdb32244798ba1fee43664c6b07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee7b76a0bc6c4a4dba659100df1c09cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d7038e38a9744c996ecf23313db90e7",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c377693c7d2246f9897c4dc11a58220a",
            "value": 25
          }
        },
        "fe4d1aa1302d438cb826a4bdf96a0c62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
