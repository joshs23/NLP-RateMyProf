{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1A8MhXtJTGi"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gqZP7THdu4MS"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip show transformers\n",
        "%pip show accelerate\n",
        "%pip install transformers[torch] -U\n",
        "%pip install accelerate -U\n",
        "%pip install transformers\n",
        "%pip install pytorch-lightning\n",
        "%pip install --upgrade transformers\n",
        "%pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERNlGyweKUhm"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfScIJapKW5X",
        "outputId": "1390ab50-5650-4854-c6cf-29bda7c7cd09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Toxic train examples\n",
            "                                              comment_text  toxic  obscene  \\\n",
            "680779   I commented on this last week on the Kiszla st...    0.0      0.0   \n",
            "465571   We should store all illegals in truck bodies t...    1.0      0.0   \n",
            "1710822  You're beginning to sound like Saddam's spokes...    0.0      0.0   \n",
            "1727503  Weird comment. If the environmentalists caused...    0.0      0.0   \n",
            "\n",
            "         sexual_explicit   threat    insult  identity_attack  \n",
            "680779               0.0  0.00000  0.000000           0.0000  \n",
            "465571               0.0  0.21875  0.140625           0.4375  \n",
            "1710822              0.0  0.00000  0.200000           0.0000  \n",
            "1727503              0.0  0.00000  0.000000           0.0000  \n",
            "Toxic test examples\n",
            "                                              comment_text  toxic  obscene  \\\n",
            "1610665  Naturally you can feel it in your urine. \\nTha...    0.0      0.0   \n",
            "495126   Yum!  What's not to love: water+maple syrup - ...    0.0      0.0   \n",
            "431396   Catou I will wager that mutual fund sales will...    0.0      0.0   \n",
            "1295718  \"The shortage of priests is not a shortage of ...    0.0      0.0   \n",
            "\n",
            "         sexual_explicit  threat  insult  identity_attack  \n",
            "1610665              0.2     0.0     0.0              0.0  \n",
            "495126               0.0     0.0     0.0              0.0  \n",
            "431396               0.0     0.0     0.0              0.0  \n",
            "1295718              0.0     0.0     0.0              0.0  \n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import os\n",
        "import gdown\n",
        "\n",
        "\n",
        "# 1. Prepare Dataset\n",
        "# 2. Load pretrained Tokenizer, call it with dataset -> encoding\n",
        "# 3. Build PyTorth Dataset with encodings\n",
        "# 4. Load pretrained Model\n",
        "# 5. Load HF Trainer and train it\n",
        "\n",
        "file_id = '1E5v6t-y2Pzeyi5C-amlYibp2cXUN0MLW'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "file_path = 'all_data.csv'\n",
        "if not os.path.exists(file_path):\n",
        "    # Download the file\n",
        "    gdown.download(url, file_path, quiet=False)\n",
        "\n",
        "# Read the csv file\n",
        "all_data = pd.read_csv(file_path, engine='python')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "toxicity_train_df, toxicity_test_df = train_test_split(all_data, test_size=0.40, random_state=42)\n",
        "\n",
        "# List of categories to check\n",
        "categories_to_check = ['obscene', 'sexual_explicit', 'threat', 'insult', 'identity_attack']\n",
        "\n",
        "toxicity_train_df[categories_to_check] = toxicity_train_df[categories_to_check].apply(pd.to_numeric, errors='coerce')\n",
        "toxicity_test_df[categories_to_check] = toxicity_test_df[categories_to_check].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Check if any category is above the 0.33 threshold\n",
        "toxicity_train_df['toxic'] = (toxicity_train_df[categories_to_check] >= 0.33).any(axis=1).astype(float)\n",
        "toxicity_test_df['toxic'] = (toxicity_test_df[categories_to_check] >= 0.33).any(axis=1).astype(float)\n",
        "\n",
        "# Convert boolean values to 1.0 for True and 0.0 for False\n",
        "toxicity_train_df['toxic'] = toxicity_train_df['toxic'].astype(float)\n",
        "toxicity_test_df['toxic'] = toxicity_test_df['toxic'].astype(float)\n",
        "\n",
        "toxicity_train_df = toxicity_train_df[['comment_text', 'toxic', 'obscene', 'sexual_explicit', 'threat', 'insult', 'identity_attack']]\n",
        "toxicity_test_df = toxicity_test_df[['comment_text', 'toxic', 'obscene', 'sexual_explicit', 'threat', 'insult', 'identity_attack']]\n",
        "\n",
        "# Can be adjusted to downsample training data\n",
        "sample_rate = 1.0\n",
        "\n",
        "toxicity_train_df = toxicity_train_df.sample(frac=sample_rate, random_state=42)\n",
        "\n",
        "print(\"Toxic train examples\")\n",
        "print(toxicity_train_df.head(4))\n",
        "\n",
        "print(\"Toxic test examples\")\n",
        "print(toxicity_test_df.head(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckNEOfOt7JY0"
      },
      "source": [
        "Test Lengths of DFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEr4-GKc7LG4",
        "outputId": "690e5068-da5c-4b56-dc27-078cf1810669"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1199709\n"
          ]
        }
      ],
      "source": [
        "print(len(toxicity_train_df))\n",
        "# print(len(toxicity_test_df))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCaSSAkv-L2D"
      },
      "source": [
        "# Visualization of toxicity in train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "Wh3Wr23h-Nwl",
        "outputId": "06c4333c-ba39-4fc5-a7b8-dae8aa14f600"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Count toxic and non-toxic comments\n",
        "toxic_count = toxicity_train_df['toxic'].sum()\n",
        "non_toxic_count = len(toxicity_train_df) - toxic_count\n",
        "\n",
        "# Plot side-by-side bars for toxic and non-toxic comments\n",
        "labels = ['Toxic Comments', 'Non-Toxic Comments']\n",
        "counts = [toxic_count, non_toxic_count]\n",
        "\n",
        "plt.bar(labels, counts, color=['red', 'blue'])\n",
        "plt.ylabel('Comment Count')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQBDfIDTAVmi"
      },
      "source": [
        "# Visualization of toxicity in test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "vMgpw28TAYN6",
        "outputId": "54a743e7-fde6-4c07-c1a7-81c9039afa45"
      },
      "outputs": [],
      "source": [
        "# # Count toxic and non-toxic comments\n",
        "# toxic_count = toxicity_test_df['toxic'].sum()\n",
        "# non_toxic_count = len(toxicity_test_df) - toxic_count\n",
        "\n",
        "# # Plot side-by-side bars for toxic and non-toxic comments\n",
        "# labels = ['Toxic Comments', 'Non-Toxic Comments']\n",
        "# counts = [toxic_count, non_toxic_count]\n",
        "\n",
        "# plt.bar(labels, counts, color=['red', 'blue'])\n",
        "# plt.ylabel('Comment Count')\n",
        "\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWP0mBB9ZFf4"
      },
      "source": [
        "# Splitting and Labelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LUVKLSjZKHn",
        "outputId": "2c90ef76-9c00-4d86-de95-618e01402663"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_texts:\n",
            "[\"I commented on this last week on the Kiszla story of Dennison going to be a factor. Not only was he a factor, but the refs and home field was something Denver didn't handle well at all. The games aren't fixed but the refs are instructed to keep things close I am certain. Winning on the road is something that takes discipline and focus. They'll learn but it sucks to watch it happen.\", 'We should store all illegals in truck bodies then ask them if they are ready to return to Mexico.', \"You're beginning to sound like Saddam's spokesman Chemical Ali...\", 'Weird comment. If the environmentalists caused the contaminations you might have a point.', 'canadian patriot writes:\\n\\n\"KGB bloggers are sure trying hard to make Pukin a silk purse from a sow\\'s ear. \\n\\nEven a face lift and elevator shoes cannot hide a Slav thug.\"\\n\\nAnd Naddaway gives patriot\\'s post a \"Disagree\" vote.\\n\\nNaddaway postulates that a face lift and elevator shoes can, indeed, after all, hide a slavic thug.']\n",
            "train_labels:\n",
            "[0.0, 1.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ],
      "source": [
        "model_name = \"roberta-base\"\n",
        "\n",
        "# Reset index to ensure consistency\n",
        "toxicity_train_df.reset_index(drop=True, inplace=True)\n",
        "# toxicity_test_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Select relevant columns from DataFrame and drop NaN values\n",
        "train_data = toxicity_train_df[['comment_text', 'toxic']].dropna()\n",
        "# test_data = toxicity_test_df[['comment_text', 'toxic']].dropna()\n",
        "\n",
        "# Extract features and labels\n",
        "train_texts = train_data['comment_text'].tolist()\n",
        "train_labels = train_data['toxic'].tolist()\n",
        "# test_texts = test_data['comment_text'].tolist()\n",
        "# test_labels = test_data['toxic'].tolist()\n",
        "\n",
        "# Print examples of texts & labels\n",
        "print(\"train_texts:\")\n",
        "print(train_texts[:5])\n",
        "print(\"train_labels:\")\n",
        "print(train_labels[:5])\n",
        "# print(\"test_texts\")\n",
        "# print(test_texts[:5])\n",
        "# print(\"test_labels:\")\n",
        "# print(test_labels[:5])\n",
        "\n",
        "# Split train data into train and validation sets\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PaVNtTit2tc"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758,
          "referenced_widgets": [
            "861da291e2084362a00b05a928f5b57b",
            "6a7d4fa147e74871a21dbb4ee5a353fb",
            "ee7b76a0bc6c4a4dba659100df1c09cc",
            "71ffb97f0bfb43ca8dce48eac582d6a4",
            "5b3c8c081de34fdc8232097c91302959",
            "7806d6aef3384a95bbcb059026675b41",
            "4b8a142ac6734ec7be44aa9eab704f54",
            "4d7038e38a9744c996ecf23313db90e7",
            "c377693c7d2246f9897c4dc11a58220a",
            "4062f1c3e24e46b994579201868f1808",
            "acdc79b1ab4a4c50a968bc5a1fba5321",
            "9a2aed7188104aff98c54719dd021070",
            "96b9e76620cd47148ccce1d8797221f3",
            "e091b5a251244d40b9bbbb526ef96efc",
            "65c1165edbb3402eb34df5e4dabd1d7c",
            "e037d6fd15234cf79d58cac63e5af9ce",
            "07f5c33c79e84d549a4a811d26fea600",
            "4836d62b4e084cd381c06ab2dfdee2e4",
            "e5ed7fdb32244798ba1fee43664c6b07",
            "d95e46ccaca2474b8d7be4e45ef8a0e6",
            "8e9ec62850d446fa9bdca90329d601e7",
            "1780cccf94454549925d62aef8a7d509",
            "85b9bc4d86984031916de614f50e4066",
            "47c5ecde15cf414f8a64584481ebaca1",
            "be4b2303100047dc8e06eff0ef408272",
            "3f06cbd465bc48a9959403a5af3d3ac8",
            "49bfd54efdbd49e185d852874d45b5f5",
            "1810f3f8e653444d835204d0cf40eb3b",
            "debb3fdcf84941db8c33237bffb6e807",
            "6153f6b9e2e44c9f817a19c64800a125",
            "2637afb72efc4afc89094aaf79ab36dc",
            "dd76675ac7b94ff0bd4000a8b6e60d65",
            "1841c5ce234548e28720a17345a73214",
            "db9cef9976b4412788705df75556a2d7",
            "d36dc922720a4b86b828eb4abf00a154",
            "e092379b6482464d955cca2f53c65c77",
            "e0071103de184a92b86c4d39f1e9c338",
            "473ae49ca3824b54adeaed2766a8858d",
            "8234948dad6148829bbf4d612faa55bf",
            "75e95696ae84420e8edfe6cc29df9248",
            "27192ce0964f402aa831e0933053ebda",
            "e214bd6657414291a39d4ed39a95aac5",
            "90097f2f6b6342c6bb00afb88b3aa1cc",
            "c9d2299f42ff415fb14bf2e520d31f2c",
            "3e931a4475d6421bae6c1648a486a580",
            "5d458a133366465097e0a81302ae6ee8",
            "1c762652db104eb6968c0638d6f2172b",
            "bc51d348e8c54caf99c15e14068e0fb7",
            "b8910cf7e8ff406fa4595ce96f53f5f7",
            "e3b62d42149a42a485e01c3defd5c61b",
            "71f022bc04c94c83a51dba65467c1972",
            "fe4d1aa1302d438cb826a4bdf96a0c62",
            "b11cb51d253e4296a6fb89d8ddba74ee",
            "e5c232d524464dec8e0667b8c57de142",
            "41ac3ca4bc184212b66f1f63453a89da"
          ]
        },
        "id": "m54fSxNKt4oC",
        "outputId": "bcc67c5a-c9a7-42c3-fec9-d7d8a5fea187"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels)\n\u001b[0;32m     18\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m RobertaTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroberta-base\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m train_encodings \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m val_encodings \u001b[38;5;241m=\u001b[39m tokenizer(val_texts, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# test_encodings = tokenizer(test_texts, truncation=True, padding=True)\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2883\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2881\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2882\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2883\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2885\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
            "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2969\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2964\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2965\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2966\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2967\u001b[0m         )\n\u001b[0;32m   2968\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[1;32m-> 2969\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2971\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2985\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2986\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2987\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2988\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m   2990\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   2991\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3007\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3008\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3160\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   3150\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   3151\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   3152\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   3153\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3157\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3158\u001b[0m )\n\u001b[1;32m-> 3160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3162\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3169\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3170\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3178\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\tokenization_utils.py:803\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    801\u001b[0m     ids, pair_ids \u001b[38;5;241m=\u001b[39m ids_or_pair_ids\n\u001b[1;32m--> 803\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m \u001b[43mget_input_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(pair_ids) \u001b[38;5;28;01mif\u001b[39;00m pair_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    805\u001b[0m input_ids\u001b[38;5;241m.\u001b[39mappend((first_ids, second_ids))\n",
            "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\tokenization_utils.py:770\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus.<locals>.get_input_ids\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_input_ids\u001b[39m(text):\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 770\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    771\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(tokens)\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n",
            "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\tokenization_utils.py:617\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize\u001b[1;34m(self, text, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m         tokenized_text\u001b[38;5;241m.\u001b[39mappend(token)\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 617\u001b[0m         tokenized_text\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    618\u001b[0m \u001b[38;5;66;03m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenized_text\n",
            "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\transformers\\models\\roberta\\tokenization_roberta.py:270\u001b[0m, in \u001b[0;36mRobertaTokenizer._tokenize\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Tokenize a string.\"\"\"\u001b[39;00m\n\u001b[0;32m    269\u001b[0m bpe_tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    271\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    272\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbyte_encoder[b] \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m token\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    273\u001b[0m     )  \u001b[38;5;66;03m# Maps all our bytes to unicode strings, avoiding control tokens of the BPE (spaces in our case)\u001b[39;00m\n\u001b[0;32m    274\u001b[0m     bpe_tokens\u001b[38;5;241m.\u001b[39mextend(bpe_token \u001b[38;5;28;01mfor\u001b[39;00m bpe_token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbpe(token)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
            "File \u001b[1;32mc:\\Users\\adity\\anaconda3\\envs\\myenv\\lib\\site-packages\\regex\\regex.py:338\u001b[0m, in \u001b[0;36mfindall\u001b[1;34m(pattern, string, flags, pos, endpos, overlapped, concurrent, timeout, ignore_unused, **kwargs)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a list of all matches in the string. The matches may be overlapped\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mif overlapped is True. If one or more groups are present in the pattern,\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;124;03mreturn a list of groups; this will be a list of tuples if the pattern has\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03mmore than one group. Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[0;32m    337\u001b[0m pat \u001b[38;5;241m=\u001b[39m _compile(pattern, flags, ignore_unused, kwargs, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcurrent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "\n",
        "\n",
        "class ToxicDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx]).float()\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
        "# test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
        "\n",
        "train_dataset = ToxicDataset(train_encodings, train_labels)\n",
        "val_dataset = ToxicDataset(val_encodings, val_labels)\n",
        "# test_dataset = ToxicDataset(test_encodings, test_labels)\n",
        "\n",
        "print(\"Train Dataset\")\n",
        "# Iterate over train_dataset and print some samples\n",
        "for i in range(2):  # Print first 2 samples\n",
        "    sample = train_dataset[i]\n",
        "    print(f\"Sample {i + 1}:\")\n",
        "    # Convert input_ids tensor to list and access its keys\n",
        "    encoding_keys = tokenizer.convert_ids_to_tokens(sample[\"input_ids\"].tolist())\n",
        "    print(\"Encoding keys:\", encoding_keys)  # Print keys of encoding\n",
        "    print(\"Label:\", sample[\"labels\"].item())  # Print label\n",
        "    print()\n",
        "\n",
        "print(\"Val Dataset\")\n",
        "# Iterate over val dataset and print some samples\n",
        "for i in range(2):  # Print first 2 samples\n",
        "    sample = val_dataset[i]\n",
        "    print(f\"Sample {i + 1}:\")\n",
        "    # Convert input_ids tensor to list and access its keys\n",
        "    encoding_keys = tokenizer.convert_ids_to_tokens(sample[\"input_ids\"].tolist())\n",
        "    print(\"Encoding keys:\", encoding_keys)  # Print keys of encoding\n",
        "    print(\"Label:\", sample[\"labels\"].item())  # Print label\n",
        "    print()\n",
        "\n",
        "print(\"Test Dataset\")\n",
        "# Iterate over test dataset and print some samples\n",
        "for i in range(2):  # Print first 2 samples\n",
        "    # sample = test_dataset[i]\n",
        "    # print(f\"Sample {i + 1}:\")\n",
        "    # Convert input_ids tensor to list and access its keys\n",
        "    encoding_keys = tokenizer.convert_ids_to_tokens(sample[\"input_ids\"].tolist())\n",
        "    print(\"Encoding keys:\", encoding_keys)  # Print keys of encoding\n",
        "    print(\"Label:\", sample[\"labels\"].item())  # Print label\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9EcJcm1nJkP"
      },
      "source": [
        "# Native PyTorch (instead of HF Trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqw8qYpfmtl_",
        "outputId": "64a6f67e-0e9c-4f2f-ed14-d6edf233b314"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "import random\n",
        "\n",
        "# Set random seed for reproducability\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Access GPU or CPU depending on status\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# Grab generic roberta-base model to be fine tuned\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=1)\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "# Initialize training params\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "optim = AdamW(model.parameters(), lr=1e-5)\n",
        "num_train_epochs = 1\n",
        "\n",
        "# Total number of training steps\n",
        "total_steps = len(train_loader) * num_train_epochs\n",
        "\n",
        "# Create the learning rate scheduler\n",
        "scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Fine-tuned roberta-base model\n",
        "for epoch in range(num_train_epochs):\n",
        "  total_loss = 0.0\n",
        "  for batch_idx, batch in enumerate(train_loader):\n",
        "      input_ids = batch['input_ids'].to(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      labels = batch['labels'].to(device)\n",
        "\n",
        "      outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "      loss = outputs[0]  # No normalization by gradient_accumulation_steps\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      # Perform an optimization step after every batch\n",
        "      optim.step()\n",
        "\n",
        "      # Update the learning rate\n",
        "      scheduler.step()\n",
        "\n",
        "      optim.zero_grad()\n",
        "\n",
        "      if (batch_idx + 1) % 1 == 0:  # Print progress every 50 batches\n",
        "          print(f\"Epoch [{epoch + 1}/{num_train_epochs}], Batch [{batch_idx + 1}/{len(train_loader)}], Loss: {total_loss / (batch_idx + 1):.4f}\")\n",
        "\n",
        "  print(f\"Epoch [{epoch + 1}/{num_train_epochs}], Average Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Store the fine-tuned model for later use\n",
        "model.save_pretrained('usr/fine_tuned_roberta_RETRAINED')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECHyv7V2o9ye"
      },
      "source": [
        "Download file paths (if desired)\n",
        "\n",
        "Sometimes can alter the json file and cause the subsequent code cells to fail. Hence, commented out for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "8juZkK6dcn6m",
        "outputId": "57412e89-1582-4dd4-8cf8-fb4201167585"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# # Paste the path you copied as the argument to files.download()\n",
        "\n",
        "# from tqdm import tqdm\n",
        "# from google.colab import files\n",
        "\n",
        "# # File paths to download\n",
        "# file_paths = ['/usr/fine_tuned_roberta_model_2/config.json', '/usr/fine_tuned_roberta_model_2/model.safetensors']\n",
        "\n",
        "# # Loop through each file and download with tqdm progress bar\n",
        "# for file_path in file_paths:\n",
        "#     with open(file_path, 'wb') as f:\n",
        "#         with tqdm(unit='B', unit_scale=True, unit_divisor=1024, miniters=1,\n",
        "#                   desc=file_path.split('/')[-1]) as pbar:\n",
        "#             # Download the file\n",
        "#             files.download(file_path)\n",
        "#             # Manually update progress bar\n",
        "#             pbar.update()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60_Yekc0nJdh"
      },
      "source": [
        "# Default RoBERTa test as baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfSPaPT-zglZ",
        "outputId": "17a6b1b6-2107-4346-b51a-0b4998d949b4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import RobertaTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import random\n",
        "\n",
        "# Set a fixed state for randomness\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Load the tokenizer and model for inference\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('roberta-base')\n",
        "\n",
        "\n",
        "# Move the model to CPU if it's on CUDA device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Put the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Function to convert LABEL_0 to 'no'\n",
        "def convert_label(prediction):\n",
        "    return 'no' if prediction[0]['label'] == 'LABEL_0' else 'yes'\n",
        "\n",
        "global count\n",
        "count = 0\n",
        "\n",
        "def predict_label(row):\n",
        "    global count\n",
        "    text_to_predict = row['comment_text']\n",
        "\n",
        "    encoding = tokenizer(text_to_predict, return_tensors='pt', padding=True, truncation=True)\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.sigmoid(logits).cpu().numpy().flatten()\n",
        "    binary_label = 1 if ((np.abs(probabilities[1] - probabilities[0]) <= 0.061) and (probabilities[0] < 0.5425)) else 0\n",
        "    count = count + 1\n",
        "    if (count % 1000 == 0):\n",
        "      print(count)\n",
        "    if(count < 10):\n",
        "      # Print out some examples of stream comments and their respective probabilities and label (toxic/non-toxic)\n",
        "      print(text_to_predict)\n",
        "      print(probabilities)\n",
        "      # The difference in probabilities represents a confidence interval which is also important to evaluate\n",
        "      print(np.abs(probabilities[1] - probabilities[0]))\n",
        "      print(binary_label)\n",
        "    return binary_label\n",
        "\n",
        "# Load the Twitch dataset\n",
        "twitch_df = pd.read_csv('hasanAbiTest.csv')\n",
        "print(len(twitch_df))\n",
        "\n",
        "# Apply the prediction function to each row in the DataFrame\n",
        "twitch_df['base_prediction'] = twitch_df.apply(predict_label, axis=1)\n",
        "\n",
        "# Assuming 'LABEL_0' corresponds to 'no'\n",
        "prediction_counts = twitch_df['base_prediction'].value_counts()\n",
        "print(prediction_counts)\n",
        "\n",
        "# Print the counts\n",
        "print(\"Count of 'no':\", prediction_counts[0.0])\n",
        "print(\"Count of 'yes':\", prediction_counts[1.0])  # Adjust the label if needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ipCWIyGLDfq"
      },
      "source": [
        "# Base Toxic Word Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "id": "YDHo9RJ-LL3Q",
        "outputId": "09101f05-848b-4711-c76f-2da2907d242c"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "# Download NLTK resources (run only once)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "print(twitch_df.info())\n",
        "\n",
        "# Filter toxic comments\n",
        "toxic_comments = twitch_df[twitch_df['base_prediction'] == 1]['comment']\n",
        "print(toxic_comments.head(5))\n",
        "\n",
        "# Initialize NLTK stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Extend the stop words list with additional common words to exclude\n",
        "additional_stop_words = ['today', \"don't\", 'like', 'know', 'and', 'the',\n",
        "                         'get', 'HasanAbi', 'hasanabi', 'Hasan', 'hasan', 'Abi',\n",
        "                         'dont', ',', 'got', 'cant', 'make',\n",
        "                         'see', 'im', 'make', 'think', 'one', 'every',\n",
        "                         'take', 'day', 'really', 'Tier', 'tier', 'Tier 1',\n",
        "                         '1', 'Theyve', 'theyve', 'going', 'subscribed', 'months']  # Add more words as needed\n",
        "stop_words.update(additional_stop_words)\n",
        "\n",
        "# Remove punctuation from comments\n",
        "def remove_punctuation(text):\n",
        "    return ''.join([char for char in text if char not in string.punctuation])\n",
        "\n",
        "cleaned_comments = ' '.join([comment for comment in toxic_comments])\n",
        "cleaned_comments = remove_punctuation(cleaned_comments)\n",
        "\n",
        "# Tokenize the cleaned comments\n",
        "tokens = nltk.word_tokenize(cleaned_comments)\n",
        "\n",
        "# Remove stop words\n",
        "tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "# Calculate word frequencies\n",
        "freq_dist = nltk.FreqDist(tokens)\n",
        "\n",
        "# Generate the word cloud with frequencies\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(freq_dist)\n",
        "\n",
        "# Plot the word cloud\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzL8EQmjdZao",
        "outputId": "d0edad07-04ca-4fc0-c42d-1a8b5ba8f11f"
      },
      "outputs": [],
      "source": [
        "!pip install better-profanity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgA8eGog8O1S"
      },
      "source": [
        "# Fine-Tuned Roberta on Cleaned UWB Review Dataset stream dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rodAVSjc8RRu",
        "outputId": "0122803c-43d5-4050-ed2d-68c45d6f66f0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import RobertaTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import random\n",
        "from better_profanity import profanity\n",
        "\n",
        "# Set a fixed state for randomness\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)  # If using CUDA\n",
        "\n",
        "# Load the tokenizer and model for inference\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('fine_tuned_roberta')\n",
        "\n",
        "# Move the model to CPU if it's on CUDA device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Put the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Function to convert LABEL_0 to 'no'\n",
        "def convert_label(prediction):\n",
        "    return 'no' if prediction[0]['label'] == 'LABEL_0' else 'yes'\n",
        "\n",
        "def contains_profanity(text):\n",
        "    return profanity_check.predict([text])[0]\n",
        "\n",
        "global count\n",
        "global sub_mention\n",
        "sub_mention = False\n",
        "profanity_in = False\n",
        "count = 0\n",
        "\n",
        "def predict_label(row):\n",
        "    global count\n",
        "    global sub_mention\n",
        "    text_to_predict = row['Review-Body']\n",
        "    if pd.isnull(text_to_predict):\n",
        "      text_to_predict = \"No Comments\" \n",
        "    # Filter out mentionings of Twitch subscriptions and tiers\n",
        "    sub_mention = any(keyword in text_to_predict for keyword in [\"Tier 1\", \"subscribed with Prime\", \"subbed using Prime\"])\n",
        "    # Leverages better profanity to catch additional profanity occurences\n",
        "    profanity_in = profanity.contains_profanity(text_to_predict)\n",
        "    encoding = tokenizer(text_to_predict, return_tensors='pt', padding=True, truncation=True)\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.sigmoid(logits).cpu().numpy().flatten()\n",
        "    binary_label = 1 if profanity_in or (np.abs(probabilities[0]) > 0.56 and not sub_mention) else 0\n",
        "    count = count + 1\n",
        "    if (count % 1000 == 0):\n",
        "      print(count)\n",
        "    if(count < 25):\n",
        "      # Print out some examples of stream comments and their respective probabilities and label (toxic/non-toxic)\n",
        "      print(text_to_predict)\n",
        "      print(np.abs(probabilities[0]))\n",
        "      print(binary_label)\n",
        "    return binary_label\n",
        "\n",
        "# Load the Twitch dataset\n",
        "twitch_df = pd.read_csv('Cleaned_UW_RMP.csv')\n",
        "print(f\"Total length of test: {len(twitch_df)}\")\n",
        "\n",
        "# Apply the prediction function to each row in the DataFrame\n",
        "twitch_df['roberta_UWBR_prediction'] = twitch_df.apply(predict_label, axis=1)\n",
        "\n",
        "prediction_counts = twitch_df['roberta_UWBR_prediction'].value_counts()\n",
        "print(prediction_counts)\n",
        "\n",
        "# Print the counts\n",
        "print(\"Count of 'no':\", prediction_counts[0.0])\n",
        "print(\"Count of 'yes':\", prediction_counts[1.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYg7iiHEIZNf"
      },
      "source": [
        "Note the ***detection of new toxic words*** not found in previous stream: Lefters, Libbers, Hoggers (assuming political connotations).\n",
        "\n",
        "Note the ***detection of user toxicity*** such as \"Yelling at Trolls\", and \"I'm not trolling\", \"CLICKBAIT\".\n",
        "\n",
        "Note the filtering out of typical Twitch platform messages subscription mentioning: \"Tier 1, has subscribed, etc\".\n",
        "\n",
        "See Excel file for more details if curious."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZrIc4M6EMzp"
      },
      "source": [
        "Save Predictions for Fine-Tuned Wikipedia Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tp30-AokERiM"
      },
      "outputs": [],
      "source": [
        "!pip install openpyxl\n",
        "# Define the file path for the Excel file\n",
        "excel_file_path = \"/usr/roberta_cardiff_UWBR_predictions.xlsx\"\n",
        "\n",
        "# Save the 'roberta_wiki_prediction' column to an Excel file\n",
        "twitch_df['roberta_UWBR_prediction'].to_excel(excel_file_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhFsI8gFLTjn"
      },
      "source": [
        "# Fine-Tuned Wikipedia Toxic Word Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "eJwuzcFwLYbd",
        "outputId": "9fc61713-5ba9-44aa-d53d-2faf1c4770ee"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "# Download NLTK resources (run only once)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Filter toxic comments\n",
        "toxic_comments = twitch_df[twitch_df['roberta_wiki_prediction'] == 1]['comment']\n",
        "print(toxic_comments.head(5))\n",
        "\n",
        "batch_size = 1000  # Set the batch size\n",
        "num_rows = len(twitch_df)\n",
        "with open('union_output.txt', 'w') as f:\n",
        "    for start in range(0, num_rows, batch_size):\n",
        "        end = min(start + batch_size, num_rows)\n",
        "        for index, row in twitch_df.iloc[start:end].iterrows():\n",
        "            f.write(str(row['roberta_wiki_prediction']) + '\\n')\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download('union_output.txt')\n",
        "\n",
        "# Initialize NLTK stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Extend the stop words list with additional common words to exclude\n",
        "additional_stop_words = ['today', \"don't\", 'like', 'know', 'and', 'the',\n",
        "                         'get', 'HasanAbi', 'hasanabi', 'Hasan', 'hasan', 'Abi',\n",
        "                         'dont', ',', 'got', 'cant', 'make',\n",
        "                         'see', 'im', 'make', 'think', 'one', 'every',\n",
        "                         'take', 'day', 'really']  # Add more words as needed\n",
        "stop_words.update(additional_stop_words)\n",
        "\n",
        "# Remove punctuation from comments\n",
        "def remove_punctuation(text):\n",
        "    return ''.join([char for char in text if char not in string.punctuation])\n",
        "\n",
        "cleaned_comments = ' '.join([comment for comment in toxic_comments])\n",
        "cleaned_comments = remove_punctuation(cleaned_comments)\n",
        "\n",
        "# Tokenize the cleaned comments\n",
        "tokens = nltk.word_tokenize(cleaned_comments)\n",
        "\n",
        "# Remove stop words\n",
        "tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "# Calculate word frequencies\n",
        "freq_dist = nltk.FreqDist(tokens)\n",
        "\n",
        "# Generate the word cloud with frequencies\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(freq_dist)\n",
        "\n",
        "# Plot the word cloud\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prbHe2ke_sJZ"
      },
      "source": [
        "# Preprocessing on Twitch Union dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q7VWNih_xYV",
        "outputId": "57d17fd0-c77b-4ed1-9c21-e8c55214d92f"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# 1. Prepare Dataset\n",
        "# 2. Load pretrained Tokenizer, call it with dataset -> encoding\n",
        "# 3. Build PyTorth Dataset with encodings\n",
        "# 4. Load pretrained Model\n",
        "# 5. Load HF Trainer and train it\n",
        "\n",
        "# Train Data (Roberta + Llama Union), 11449 rows\n",
        "toxicity_train_df = pd.read_csv('toxic_union.csv',  on_bad_lines='skip')\n",
        "toxicity_train_df = toxicity_train_df.dropna()\n",
        "\n",
        "# Test Data - 7287 rows after pre-processing\n",
        "toxicity_test_df = pd.read_csv('toxicity_test.csv', on_bad_lines='skip', quoting=csv.QUOTE_NONE)\n",
        "toxicity_test_df = toxicity_test_df.dropna()\n",
        "\n",
        "# Only check these categories in toxicity_test since train is our union csv\n",
        "# built from the previous fine-tuning and training cells\n",
        "categories_to_check = ['obscene', 'sexual_explicit', 'threat', 'insult', 'identity_attack']\n",
        "\n",
        "toxicity_test_df[categories_to_check] = toxicity_test_df[categories_to_check].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Check if any category is above the 0.33 threshold\n",
        "toxicity_test_df['toxic'] = (toxicity_test_df[categories_to_check] >= 0.33).any(axis=1).astype(float)\n",
        "toxicity_test_df['toxic'] = toxicity_test_df['toxic'].astype(float)\n",
        "toxicity_test_df = toxicity_test_df[['comment_text', 'toxic', 'obscene', 'sexual_explicit', 'threat', 'insult', 'identity_attack']]\n",
        "\n",
        "print(\"Toxic train examples\")\n",
        "print(toxicity_train_df.head(4))\n",
        "\n",
        "print(\"Toxic test examples\")\n",
        "print(toxicity_test_df.head(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cFDObnXpwqm"
      },
      "source": [
        "Test DF lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkhGq7HqMhLC",
        "outputId": "6c3c88b7-f2b8-4371-e3fe-43c7d9fa8cf5"
      },
      "outputs": [],
      "source": [
        "print(len(toxicity_train_df))\n",
        "print(len(toxicity_test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcLMOYf6Eaqf"
      },
      "source": [
        "# Visualization of Toxicity in Union Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "bnpI6vCREizW",
        "outputId": "0f6f5455-0c97-4669-a423-0f1f69f36cd7"
      },
      "outputs": [],
      "source": [
        "# Count toxic and non-toxic comments\n",
        "toxic_count = toxicity_train_df['union'].sum()\n",
        "non_toxic_count = len(toxicity_train_df) - toxic_count\n",
        "\n",
        "# Plot side-by-side bars for toxic and non-toxic comments\n",
        "labels = ['Toxic Comments', 'Non-Toxic Comments']\n",
        "counts = [toxic_count, non_toxic_count]\n",
        "\n",
        "plt.bar(labels, counts, color=['red', 'blue'])\n",
        "plt.ylabel('Comment Count')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BKaGeUaEw1w"
      },
      "source": [
        "# Union Dataset Wordcloud\n",
        "\n",
        "***What are the most common toxic words in our Union Dataset?***\n",
        "\n",
        "Union Dataset: Represents the union of Llama 7-b zero-shot labeling, and RoBERTa NLP model fine-tuned on Wikipedia comments on toxic Twitch comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "kXb3w4KdEzda",
        "outputId": "586c3227-afb0-4e22-d60d-2bc5cdc3f7d5"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "# Download NLTK resources (run only once)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Filter toxic comments\n",
        "toxic_comments = toxicity_train_df[toxicity_train_df['union'] == 1]['comment_text']\n",
        "print(toxic_comments.head(5))\n",
        "\n",
        "# Initialize NLTK stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Extend the stop words list with additional common words to exclude\n",
        "additional_stop_words = ['today', \"don't\", 'like', 'know', 'and', 'the',\n",
        "                         'get', 'HasanAbi', 'hasanabi', 'Hasan', 'hasan', 'Abi',\n",
        "                         'dont', ',', 'got', 'cant', 'make',\n",
        "                         'see', 'im', 'make', 'think', 'one', 'every',\n",
        "                         'take', 'day', 'really', 'Tier', 'tier', 'Tier 1',\n",
        "                         '1', 'Theyve', 'theyve', 'going', 'subscribed', 'months']  # Add more words as needed\n",
        "stop_words.update(additional_stop_words)\n",
        "\n",
        "# Remove punctuation from comments\n",
        "def remove_punctuation(text):\n",
        "    return ''.join([char for char in text if char not in string.punctuation])\n",
        "\n",
        "cleaned_comments = ' '.join([comment for comment in toxic_comments])\n",
        "cleaned_comments = remove_punctuation(cleaned_comments)\n",
        "\n",
        "# Tokenize the cleaned comments\n",
        "tokens = nltk.word_tokenize(cleaned_comments)\n",
        "\n",
        "# Remove stop words\n",
        "tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "# Calculate word frequencies\n",
        "freq_dist = nltk.FreqDist(tokens)\n",
        "\n",
        "# Generate the word cloud with frequencies\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(freq_dist)\n",
        "\n",
        "# Plot the word cloud\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1YXDyrvAcEQ"
      },
      "source": [
        "# Splitting & Labeling + Dataset creation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxlgXZ0JAsrX",
        "outputId": "0e692efc-90db-47ee-8578-1d03e25835e9"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "\n",
        "# Reset index to ensure consistency\n",
        "toxicity_train_df.reset_index(drop=True, inplace=True)\n",
        "toxicity_test_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Select relevant columns from DataFrame and drop NaN values\n",
        "train_data = toxicity_train_df[['comment_text', 'union']].dropna()\n",
        "test_data = toxicity_test_df[['comment_text', 'toxic']].dropna()\n",
        "\n",
        "# Extract features and labels\n",
        "train_texts = train_data['comment_text'].tolist()\n",
        "train_labels = train_data['union'].tolist()\n",
        "test_texts = test_data['comment_text'].tolist()\n",
        "test_labels = test_data['toxic'].tolist()\n",
        "\n",
        "# Print examples of texts & labels\n",
        "print(\"train_texts:\")\n",
        "print(train_texts[:5])\n",
        "print(\"train_labels:\")\n",
        "print(train_labels[:5])\n",
        "print(\"test_texts\")\n",
        "print(test_texts[:5])\n",
        "print(\"test_labels:\")\n",
        "print(test_labels[:5])\n",
        "\n",
        "# Split train data into train and validation sets\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2)\n",
        "\n",
        "\n",
        "class ToxicDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx]).float()\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
        "\n",
        "train_dataset = ToxicDataset(train_encodings, train_labels)\n",
        "val_dataset = ToxicDataset(val_encodings, val_labels)\n",
        "test_dataset = ToxicDataset(test_encodings, test_labels)\n",
        "\n",
        "print(\"Train Dataset\")\n",
        "# Iterate over train_dataset and print some samples\n",
        "for i in range(2):  # Print first 2 samples\n",
        "    sample = train_dataset[i]\n",
        "    print(f\"Sample {i + 1}:\")\n",
        "    # Convert input_ids tensor to list and access its keys\n",
        "    encoding_keys = tokenizer.convert_ids_to_tokens(sample[\"input_ids\"].tolist())\n",
        "    print(\"Encoding keys:\", encoding_keys)  # Print keys of encoding\n",
        "    print(\"Label:\", sample[\"labels\"].item())  # Print label\n",
        "    print()\n",
        "\n",
        "print(\"Val Dataset\")\n",
        "# Iterate over val dataset and print some samples\n",
        "for i in range(2):  # Print first 2 samples\n",
        "    sample = val_dataset[i]\n",
        "    print(f\"Sample {i + 1}:\")\n",
        "    # Convert input_ids tensor to list and access its keys\n",
        "    encoding_keys = tokenizer.convert_ids_to_tokens(sample[\"input_ids\"].tolist())\n",
        "    print(\"Encoding keys:\", encoding_keys)  # Print keys of encoding\n",
        "    print(\"Label:\", sample[\"labels\"].item())  # Print label\n",
        "    print()\n",
        "\n",
        "print(\"Test Dataset\")\n",
        "# Iterate over test dataset and print some samples\n",
        "for i in range(2):  # Print first 2 samples\n",
        "    sample = test_dataset[i]\n",
        "    print(f\"Sample {i + 1}:\")\n",
        "    # Convert input_ids tensor to list and access its keys\n",
        "    encoding_keys = tokenizer.convert_ids_to_tokens(sample[\"input_ids\"].tolist())\n",
        "    print(\"Encoding keys:\", encoding_keys)  # Print keys of encoding\n",
        "    print(\"Label:\", sample[\"labels\"].item())  # Print label\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIbBWay5BWT2"
      },
      "source": [
        "# Training on Union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyH82OeDBuKz",
        "outputId": "f1383efa-aff6-48ce-c821-e815d8e6417b"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import RobertaTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import AdamW\n",
        "import torch\n",
        "\n",
        "# Set random seed for reproducability\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# Access the once fine-tuned RoBERTa model we just created\n",
        "# (not the same as RoBERTa toxicity standard used below see desc for explanation)\n",
        "model = AutoModelForSequenceClassification.from_pretrained('/usr/fine_tuned_roberta_model')\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "# Initialize training parameters\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "optim = AdamW(model.parameters(), lr=1e-6)\n",
        "num_train_epochs = 1\n",
        "\n",
        "# Train on the union of Llama 7-b and RoBERTa toxicity standard\n",
        "for epoch in range(num_train_epochs):\n",
        "  total_loss = 0.0\n",
        "  for batch_idx, batch in enumerate(train_loader):\n",
        "      optim.zero_grad()\n",
        "      input_ids = batch['input_ids'].to(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      labels = batch['labels'].to(device)\n",
        "\n",
        "      outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "      loss = outputs[0]\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "\n",
        "      if (batch_idx + 1) % 50 == 0:  # Print progress every 50 batches\n",
        "          print(f\"Epoch [{epoch + 1}/{num_train_epochs}], Batch [{batch_idx + 1}/{len(train_loader)}], Loss: {total_loss / (batch_idx + 1):.4f}\")\n",
        "\n",
        "  print(f\"Epoch [{epoch + 1}/{num_train_epochs}], Average Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "model.save_pretrained('/usr/fine_tuned_roberta_model_')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfQ5N02B-4zI"
      },
      "source": [
        "***How are the RoBERTa models different?***\n",
        "\n",
        "Great question. The RoBERTa models vary in that the first one created focuses on the fine-tuning using a toxicity definition that focuses on five specific sub-categories of toxicity (insult, threat, obscene, identity_hate, sexually_explicit). This gives us a more focused definition for toxicity than the [RoBERTa toxicity standard model](https://huggingface.co/s-nlp/roberta_toxicity_classifier), which also uses Wikipedia comments, but has a more generalizable definition of toxic and features much more data. Thus, the Union represents the Union of Llama 7-b with the RoBERTa standard model as both should have a lot more context and generalizability than the once fine-tuned version of RoBERTa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-uWSB4fB0Ny"
      },
      "source": [
        "# Fine-tuned Union (RoBERTa / Llama) Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25Nw-yFYCbt6",
        "outputId": "7202a946-1840-4410-93f1-a6fb287b245a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import RobertaTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import random\n",
        "from better_profanity import profanity\n",
        "\n",
        "# Set a fixed state for randomness\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Load the tokenizer and model for inference\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('/usr/fine_tuned_roberta_model_union')\n",
        "\n",
        "# Move the model to CPU if it's on CUDA device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Put the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Function to convert LABEL_0 to 'no'\n",
        "def convert_label(prediction):\n",
        "    return 'no' if prediction[0]['label'] == 'LABEL_0' else 'yes'\n",
        "\n",
        "# Returns whether text contains profanity\n",
        "def contains_profanity(text):\n",
        "    return profanity_check.predict([text])[0]\n",
        "\n",
        "global count\n",
        "global sub_mention\n",
        "sub_mention = False\n",
        "profanity_in = False\n",
        "count = 0\n",
        "\n",
        "def predict_label(row):\n",
        "    global count\n",
        "    global sub_mention\n",
        "    text_to_predict = row['comment']\n",
        "    # Remove any generic Twitch platform subscription comments\n",
        "    sub_mention = any(keyword in text_to_predict for keyword in [\"Tier 1\", \"subscribed with Prime\", \"subbed using Prime\"])\n",
        "    # Employ profanity checker for more robust toxic comment detection in case some words or acronyms\n",
        "    # are missed initially by classifier\n",
        "    profanity_in = profanity.contains_profanity(text_to_predict)\n",
        "    encoding = tokenizer(text_to_predict, return_tensors='pt', padding=True, truncation=True)\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.sigmoid(logits).cpu().numpy().flatten()\n",
        "    binary_label = 1 if profanity_in or (np.abs(probabilities[0]) > 0.577 and not sub_mention) or (np.abs(probabilities[0]) < 0.551 and not sub_mention) else 0\n",
        "    count = count + 1\n",
        "    if (count % 1000 == 0):\n",
        "      print(count)\n",
        "    if(count < 20):\n",
        "      # Print out some examples of stream comments and their respective probabilities and label (toxic/non-toxic)\n",
        "      print(text_to_predict)\n",
        "      print(np.abs(probabilities[0]))\n",
        "      print(binary_label)\n",
        "    return binary_label\n",
        "\n",
        "# Load the Twitch dataset\n",
        "twitch_df = pd.read_csv('hasan_abi_11.19.22_test.csv')\n",
        "print(len(twitch_df))\n",
        "\n",
        "# Apply the prediction function to each row in the DataFrame\n",
        "twitch_df['union_prediction'] = twitch_df.apply(predict_label, axis=1)\n",
        "\n",
        "# Grab prediction counts\n",
        "prediction_counts = twitch_df['union_prediction'].value_counts()\n",
        "print(prediction_counts)\n",
        "\n",
        "# Print the counts\n",
        "print(\"Count of 'no':\", prediction_counts[0.0])\n",
        "print(\"Count of 'yes':\", prediction_counts[1.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ci1MzbboS7iI"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjEw6E37S8HN"
      },
      "outputs": [],
      "source": [
        "# Define the file path for the Excel file\n",
        "excel_file_path = \"/usr/roberta_union_predictions_final.xlsx\"\n",
        "\n",
        "# Save the 'roberta_wiki_prediction' column to an Excel file\n",
        "twitch_df['union_prediction'].to_excel(excel_file_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI5gubWCCeZS"
      },
      "source": [
        "# Double fine-tuned WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "vTvd_EwoChU_",
        "outputId": "dde054f0-df1c-4a7a-93ec-e852eb89a86f"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import string\n",
        "\n",
        "# Download NLTK resources (run only once)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Filter toxic comments\n",
        "toxic_comments = twitch_df[twitch_df['union_prediction'] == 1]['comment']\n",
        "print(toxic_comments.head(5))\n",
        "\n",
        "from google.colab import files\n",
        "files.download('union_output.txt')\n",
        "\n",
        "# Initialize NLTK stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Extend the stop words list with additional common words to exclude\n",
        "additional_stop_words = ['today', \"don't\", 'like', 'know', 'and', 'the',\n",
        "                         'get', 'HasanAbi', 'hasanabi', 'Hasan', 'hasan', 'Abi',\n",
        "                         'dont', ',', 'got', 'cant', 'make', 'hes', 'back',\n",
        "                         'see', 'im', 'make', 'think', 'one', 'every', 'running',\n",
        "                         'take', 'day', 'really', 'Trump', 'EPISODE', 'PODCAST', 'Episode',\n",
        "                         'Podcast', 'leftovers', 'trump', 'episode', 'podcast']  # Add more words as needed\n",
        "stop_words.update(additional_stop_words)\n",
        "\n",
        "# Remove punctuation from comments\n",
        "def remove_punctuation(text):\n",
        "    return ''.join([char for char in text if char not in string.punctuation])\n",
        "\n",
        "cleaned_comments = ' '.join([comment for comment in toxic_comments])\n",
        "cleaned_comments = remove_punctuation(cleaned_comments)\n",
        "\n",
        "# Convert all words to lowercase before removing stopwords\n",
        "tokens = [word.lower() for word in tokens]\n",
        "\n",
        "# Remove stop words\n",
        "tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "# Calculate word frequencies\n",
        "freq_dist = nltk.FreqDist(tokens)\n",
        "\n",
        "# Generate the word cloud with frequencies\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(freq_dist)\n",
        "\n",
        "# Plot the word cloud\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07f5c33c79e84d549a4a811d26fea600": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1780cccf94454549925d62aef8a7d509": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1810f3f8e653444d835204d0cf40eb3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1841c5ce234548e28720a17345a73214": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c762652db104eb6968c0638d6f2172b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe4d1aa1302d438cb826a4bdf96a0c62",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b11cb51d253e4296a6fb89d8ddba74ee",
            "value": 481
          }
        },
        "2637afb72efc4afc89094aaf79ab36dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27192ce0964f402aa831e0933053ebda": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e931a4475d6421bae6c1648a486a580": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d458a133366465097e0a81302ae6ee8",
              "IPY_MODEL_1c762652db104eb6968c0638d6f2172b",
              "IPY_MODEL_bc51d348e8c54caf99c15e14068e0fb7"
            ],
            "layout": "IPY_MODEL_b8910cf7e8ff406fa4595ce96f53f5f7"
          }
        },
        "3f06cbd465bc48a9959403a5af3d3ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd76675ac7b94ff0bd4000a8b6e60d65",
            "placeholder": "",
            "style": "IPY_MODEL_1841c5ce234548e28720a17345a73214",
            "value": "456k/456k[00:00&lt;00:00,19.4MB/s]"
          }
        },
        "4062f1c3e24e46b994579201868f1808": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41ac3ca4bc184212b66f1f63453a89da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "473ae49ca3824b54adeaed2766a8858d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47c5ecde15cf414f8a64584481ebaca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1810f3f8e653444d835204d0cf40eb3b",
            "placeholder": "",
            "style": "IPY_MODEL_debb3fdcf84941db8c33237bffb6e807",
            "value": "merges.txt:100%"
          }
        },
        "4836d62b4e084cd381c06ab2dfdee2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49bfd54efdbd49e185d852874d45b5f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b8a142ac6734ec7be44aa9eab704f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d7038e38a9744c996ecf23313db90e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b3c8c081de34fdc8232097c91302959": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d458a133366465097e0a81302ae6ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3b62d42149a42a485e01c3defd5c61b",
            "placeholder": "",
            "style": "IPY_MODEL_71f022bc04c94c83a51dba65467c1972",
            "value": "config.json:100%"
          }
        },
        "6153f6b9e2e44c9f817a19c64800a125": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65c1165edbb3402eb34df5e4dabd1d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e9ec62850d446fa9bdca90329d601e7",
            "placeholder": "",
            "style": "IPY_MODEL_1780cccf94454549925d62aef8a7d509",
            "value": "899k/899k[00:00&lt;00:00,11.0MB/s]"
          }
        },
        "6a7d4fa147e74871a21dbb4ee5a353fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7806d6aef3384a95bbcb059026675b41",
            "placeholder": "",
            "style": "IPY_MODEL_4b8a142ac6734ec7be44aa9eab704f54",
            "value": "tokenizer_config.json:100%"
          }
        },
        "71f022bc04c94c83a51dba65467c1972": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71ffb97f0bfb43ca8dce48eac582d6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4062f1c3e24e46b994579201868f1808",
            "placeholder": "",
            "style": "IPY_MODEL_acdc79b1ab4a4c50a968bc5a1fba5321",
            "value": "25.0/25.0[00:00&lt;00:00,1.25kB/s]"
          }
        },
        "75e95696ae84420e8edfe6cc29df9248": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7806d6aef3384a95bbcb059026675b41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8234948dad6148829bbf4d612faa55bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85b9bc4d86984031916de614f50e4066": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47c5ecde15cf414f8a64584481ebaca1",
              "IPY_MODEL_be4b2303100047dc8e06eff0ef408272",
              "IPY_MODEL_3f06cbd465bc48a9959403a5af3d3ac8"
            ],
            "layout": "IPY_MODEL_49bfd54efdbd49e185d852874d45b5f5"
          }
        },
        "861da291e2084362a00b05a928f5b57b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a7d4fa147e74871a21dbb4ee5a353fb",
              "IPY_MODEL_ee7b76a0bc6c4a4dba659100df1c09cc",
              "IPY_MODEL_71ffb97f0bfb43ca8dce48eac582d6a4"
            ],
            "layout": "IPY_MODEL_5b3c8c081de34fdc8232097c91302959"
          }
        },
        "8e9ec62850d446fa9bdca90329d601e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90097f2f6b6342c6bb00afb88b3aa1cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96b9e76620cd47148ccce1d8797221f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07f5c33c79e84d549a4a811d26fea600",
            "placeholder": "",
            "style": "IPY_MODEL_4836d62b4e084cd381c06ab2dfdee2e4",
            "value": "vocab.json:100%"
          }
        },
        "9a2aed7188104aff98c54719dd021070": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96b9e76620cd47148ccce1d8797221f3",
              "IPY_MODEL_e091b5a251244d40b9bbbb526ef96efc",
              "IPY_MODEL_65c1165edbb3402eb34df5e4dabd1d7c"
            ],
            "layout": "IPY_MODEL_e037d6fd15234cf79d58cac63e5af9ce"
          }
        },
        "acdc79b1ab4a4c50a968bc5a1fba5321": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b11cb51d253e4296a6fb89d8ddba74ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8910cf7e8ff406fa4595ce96f53f5f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc51d348e8c54caf99c15e14068e0fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5c232d524464dec8e0667b8c57de142",
            "placeholder": "",
            "style": "IPY_MODEL_41ac3ca4bc184212b66f1f63453a89da",
            "value": "481/481[00:00&lt;00:00,24.5kB/s]"
          }
        },
        "be4b2303100047dc8e06eff0ef408272": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6153f6b9e2e44c9f817a19c64800a125",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2637afb72efc4afc89094aaf79ab36dc",
            "value": 456318
          }
        },
        "c377693c7d2246f9897c4dc11a58220a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9d2299f42ff415fb14bf2e520d31f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d36dc922720a4b86b828eb4abf00a154": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8234948dad6148829bbf4d612faa55bf",
            "placeholder": "",
            "style": "IPY_MODEL_75e95696ae84420e8edfe6cc29df9248",
            "value": "tokenizer.json:100%"
          }
        },
        "d95e46ccaca2474b8d7be4e45ef8a0e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db9cef9976b4412788705df75556a2d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d36dc922720a4b86b828eb4abf00a154",
              "IPY_MODEL_e092379b6482464d955cca2f53c65c77",
              "IPY_MODEL_e0071103de184a92b86c4d39f1e9c338"
            ],
            "layout": "IPY_MODEL_473ae49ca3824b54adeaed2766a8858d"
          }
        },
        "dd76675ac7b94ff0bd4000a8b6e60d65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "debb3fdcf84941db8c33237bffb6e807": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0071103de184a92b86c4d39f1e9c338": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90097f2f6b6342c6bb00afb88b3aa1cc",
            "placeholder": "",
            "style": "IPY_MODEL_c9d2299f42ff415fb14bf2e520d31f2c",
            "value": "1.36M/1.36M[00:00&lt;00:00,14.9MB/s]"
          }
        },
        "e037d6fd15234cf79d58cac63e5af9ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e091b5a251244d40b9bbbb526ef96efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5ed7fdb32244798ba1fee43664c6b07",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d95e46ccaca2474b8d7be4e45ef8a0e6",
            "value": 898823
          }
        },
        "e092379b6482464d955cca2f53c65c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27192ce0964f402aa831e0933053ebda",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e214bd6657414291a39d4ed39a95aac5",
            "value": 1355863
          }
        },
        "e214bd6657414291a39d4ed39a95aac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3b62d42149a42a485e01c3defd5c61b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5c232d524464dec8e0667b8c57de142": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5ed7fdb32244798ba1fee43664c6b07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee7b76a0bc6c4a4dba659100df1c09cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d7038e38a9744c996ecf23313db90e7",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c377693c7d2246f9897c4dc11a58220a",
            "value": 25
          }
        },
        "fe4d1aa1302d438cb826a4bdf96a0c62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
